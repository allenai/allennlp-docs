

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.state_machines.transition_functions &mdash; AllenNLP 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="allennlp.tools" href="allennlp.tools.html" />
    <link rel="prev" title="allennlp.state_machines.trainers" href="allennlp.state_machines.trainers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.configure.html">allennlp.commands.configure</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.make_vocab.html">allennlp.commands.make_vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.fine_tune.html">allennlp.commands.fine_tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.elmo.html">allennlp.commands.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.dry_run.html">allennlp.commands.dry_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.find_learning_rate.html">allennlp.commands.find_learning_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.test_install.html">allennlp.commands.test_install</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.print_results.html">allennlp.commands.print_results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.configuration.html">allennlp.common.configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.from_params.html">allennlp.common.from_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tqdm.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_utils.html">allennlp.data.dataset_readers.dataset_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.babi.html">allennlp.data.dataset_readers.babi</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ccgbank.html">allennlp.data.dataset_readers.ccgbank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2000.html">allennlp.data.dataset_readers.conll2000</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.event2mind.html">allennlp.data.dataset_readers.event2mind</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.interleaving_dataset_reader.html">allennlp.data.dataset_readers.interleaving_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.masked_language_modeling.html">allennlp.data.dataset_readers.masked_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.multiprocess_dataset_reader.html">allennlp.data.dataset_readers.multiprocess_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.next_token_lm.html">allennlp.data.dataset_readers.next_token_lm</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ontonotes_ner.html">allennlp.data.dataset_readers.ontonotes_ner</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.penn_tree_bank.html">allennlp.data.dataset_readers.penn_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_dependency_parsing.html">allennlp.data.dataset_readers.semantic_dependency_parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.html">allennlp.data.dataset_readers.semantic_parsing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.wikitables.html">allennlp.data.dataset_readers.semantic_parsing.wikitables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.simple_language_modeling.html">allennlp.data.dataset_readers.simple_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.stanford_sentiment_tree_bank.html">allennlp.data.dataset_readers.stanford_sentiment_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies.html">allennlp.data.dataset_readers.universal_dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies_multilang.html">allennlp.data.dataset_readers.universal_dependencies_multilang</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.copynet_seq2seq.html">allennlp.data.dataset_readers.copynet_seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.text_classification_json.html">allennlp.data.dataset_readers.text_classification_json</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.interpret.html">allennlp.interpret</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.attackers.html">allennlp.interpret.attackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.saliency_interpreters.html">allennlp.interpret.saliency_interpreters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.basic_classifier.html">allennlp.models.basic_classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bert_for_classification.html">allennlp.models.bert_for_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser.html">allennlp.models.biaffine_dependency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser_multilang.html">allennlp.models.biaffine_dependency_parser_multilang</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biattentive_classification_network.html">allennlp.models.biattentive_classification_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bimpm.html">allennlp.models.bimpm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.constituency_parser.html">allennlp.models.constituency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.ensemble.html">allennlp.models.ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.esim.html">allennlp.models.esim</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.event2mind.html">allennlp.models.event2mind</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.graph_parser.html">allennlp.models.graph_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.language_model.html">allennlp.models.language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.masked_language_model.html">allennlp.models.masked_language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.next_token_lm.html">allennlp.models.next_token_lm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_parsing.html">allennlp.models.semantic_parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.nlvr.html">allennlp.models.semantic_parsing.nlvr</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.wikitables.html">allennlp.models.semantic_parsing.wikitables</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.atis.html">allennlp.models.semantic_parsing.atis</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.quarel.html">allennlp.models.semantic_parsing.quarel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_bert.html">allennlp.models.srl_bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_util.html">allennlp.models.srl_util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.predictors.html">allennlp.predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo.html">allennlp.modules.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.language_model_heads.html">allennlp.modules.language_model_heads</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.openai_transformer.html">allennlp.modules.openai_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_decoders.html">allennlp.modules.seq2seq_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.span_extractors.html">allennlp.modules.span_extractors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_bidirectional_lstm.html">allennlp.modules.stacked_bidirectional_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.layer_norm.html">allennlp.modules.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.pruner.html">allennlp.modules.pruner</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.maxout.html">allennlp.modules.maxout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.input_variational_dropout.html">allennlp.modules.input_variational_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.bimpm_matching.html">allennlp.modules.bimpm_matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.masked_layer_norm.html">allennlp.modules.masked_layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.sampled_softmax_loss.html">allennlp.modules.sampled_softmax_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.residual_with_layer_dropout.html">allennlp.modules.residual_with_layer_dropout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.chu_liu_edmonds.html">allennlp.nn.chu_liu_edmonds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.beam_search.html">allennlp.nn.beam_search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.semparse.html">allennlp.semparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.common.html">allennlp.semparse.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.contexts.html">allennlp.semparse.contexts</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.type_declarations.html">allennlp.semparse.type_declarations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.worlds.html">allennlp.semparse.worlds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.domain_languages.html">allennlp.semparse.domain_languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.util.html">allennlp.semparse.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_simple.html">allennlp.service.server_simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.config_explorer.html">allennlp.service.config_explorer</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.state_machines.html">allennlp.state_machines</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.states.html">allennlp.state_machines.states</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.trainers.html">allennlp.state_machines.trainers</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.state_machines.transition_functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.tools.html">allennlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callbacks.html">allennlp.training.callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callback_trainer.html">allennlp.training.callback_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.checkpointer.html">allennlp.training.checkpointer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.scheduler.html">allennlp.training.scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.momentum_schedulers.html">allennlp.training.momentum_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metric_tracker.html">allennlp.training.metric_tracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.moving_average.html">allennlp.training.moving_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.no_op_trainer.html">allennlp.training.no_op_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.tensorboard_writer.html">allennlp.training.tensorboard_writer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_base.html">allennlp.training.trainer_base</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_pieces.html">allennlp.training.trainer_pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.util.html">allennlp.training.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.pretrained.html">allennlp.pretrained</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.state_machines.html">allennlp.state_machines</a> &raquo;</li>
        
      <li>allennlp.state_machines.transition_functions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.state_machines.transition_functions.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.state_machines.transition_functions">
<span id="allennlp-state-machines-transition-functions"></span><h1>allennlp.state_machines.transition_functions<a class="headerlink" href="#module-allennlp.state_machines.transition_functions" title="Permalink to this headline">¶</a></h1>
<p>This module contains <code class="docutils literal notranslate"><span class="pre">TransitionFunctions</span></code> for state-machine-based decoders.  The
<code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> parameterizes transitions between <code class="docutils literal notranslate"><span class="pre">States</span></code>.  These <code class="docutils literal notranslate"><span class="pre">TransitionFunctions</span></code>
are all pytorch <cite>Modules`</cite> that have trainable parameters.  The <code class="xref py py-class docutils literal notranslate"><span class="pre">BasicTransitionFunction</span></code> is
simply an LSTM decoder with attention over an input utterance, and the other classes typically
subclass this and add functionality to it.</p>
<span class="target" id="module-allennlp.state_machines.transition_functions.transition_function"></span><dl class="class">
<dt id="allennlp.state_machines.transition_functions.transition_function.TransitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.state_machines.transition_functions.transition_function.</code><code class="sig-name descname">TransitionFunction</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/transition_function.py#L10-L82"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.transition_function.TransitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">typing.Generic</span></code></p>
<p>A <code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> is a module that assigns scores to state transitions in a
transition-based decoder.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> takes a <code class="docutils literal notranslate"><span class="pre">State</span></code> and outputs a ranked list of next states, ordered
by the state’s score.</p>
<p>The intention with this class is that a model will implement a subclass of
<code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> that defines how exactly you want to handle the input and what
computations get done at each step of decoding, and how states are scored.  This subclass then
gets passed to a <code class="docutils literal notranslate"><span class="pre">DecoderTrainer</span></code> to have its parameters trained.</p>
<dl class="method">
<dt id="allennlp.state_machines.transition_functions.transition_function.TransitionFunction.take_step">
<code class="sig-name descname">take_step</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">state: ~StateType</em>, <em class="sig-param">max_actions: int = None</em>, <em class="sig-param">allowed_actions: List[Set] = None</em><span class="sig-paren">)</span> &#x2192; List[~StateType]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/transition_function.py#L23-L82"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.transition_function.TransitionFunction.take_step" title="Permalink to this definition">¶</a></dt>
<dd><p>The main method in the <code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> API.  This function defines the computation
done at each step of decoding and returns a ranked list of next states.</p>
<p>The input state is <cite>grouped</cite>, to allow for efficient computation, but the output states
should all have a <code class="docutils literal notranslate"><span class="pre">group_size</span></code> of 1, to make things easier on the decoding algorithm.
They will get regrouped later as needed.</p>
<p>Because of the way we handle grouping in the decoder states, constructing a new state is
actually a relatively expensive operation.  If you know a priori that only some of the
states will be needed (either because you have a set of gold action sequences, or you have
a fixed beam size), passing that information into this function will keep us from
constructing more states than we need, which will greatly speed up your computation.</p>
<p>IMPORTANT: This method <cite>must</cite> returns states already sorted by their score, otherwise
<code class="docutils literal notranslate"><span class="pre">BeamSearch</span></code> and other methods will break.  For efficiency, we do not perform an
additional sort in those methods.</p>
<p>ALSO IMPORTANT: When <code class="docutils literal notranslate"><span class="pre">allowed_actions</span></code> is given and <code class="docutils literal notranslate"><span class="pre">max_actions</span></code> is not, we assume you
want to evaluate all possible states and do not need any sorting (e.g., this is true for
maximum marginal likelihood training that does not use a beam search).  In this case, we
may skip the sorting step for efficiency reasons.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>state</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">State</span></code></span></dt><dd><p>The current state of the decoder, which we will take a step <cite>from</cite>.  We may be grouping
together computation for several states here.  Because we can have several states for
each instance in the original batch being evaluated at the same time, we use
<code class="docutils literal notranslate"><span class="pre">group_size</span></code> for this kind of batching, and <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> for the <cite>original</cite> batch
in <code class="docutils literal notranslate"><span class="pre">model.forward.</span></code></p>
</dd>
<dt><strong>max_actions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional</span></dt><dd><p>If you know that you will only need a certain number of states out of this (e.g., in a
beam search), you can pass in the max number of actions that you need, and we will only
construct that many states (for each <cite>batch</cite> instance - <cite>not</cite> for each <cite>group</cite>
instance!).  This can save a whole lot of computation if you have an action space
that’s much larger than your beam size.</p>
</dd>
<dt><strong>allowed_actions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Set]</span></code>, optional</span></dt><dd><p>If the <code class="docutils literal notranslate"><span class="pre">DecoderTrainer</span></code> has constraints on which actions need to be evaluated (e.g.,
maximum marginal likelihood only needs to evaluate action sequences in a given set),
you can pass those constraints here, to avoid constructing state objects unnecessarily.
If there are no constraints from the trainer, passing a value of <code class="docutils literal notranslate"><span class="pre">None</span></code> here will
allow all actions to be considered.</p>
<p>This is a list because it is <cite>batched</cite> - every instance in the batch has a set of
allowed actions.  Note that the size of this list is the <code class="docutils literal notranslate"><span class="pre">group_size</span></code> in the
<code class="docutils literal notranslate"><span class="pre">State</span></code>, <cite>not</cite> the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of <code class="docutils literal notranslate"><span class="pre">model.forward</span></code>.  The training algorithm needs
to convert from the <cite>batched</cite> allowed action sequences that it has to a <cite>grouped</cite>
allowed action sequence list.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>next_states</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[State]</span></code></span></dt><dd><p>A list of next states, ordered by score.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.state_machines.transition_functions.basic_transition_function"></span><dl class="class">
<dt id="allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.state_machines.transition_functions.basic_transition_function.</code><code class="sig-name descname">BasicTransitionFunction</code><span class="sig-paren">(</span><em class="sig-param">encoder_output_dim: int</em>, <em class="sig-param">action_embedding_dim: int</em>, <em class="sig-param">input_attention: allennlp.modules.attention.attention.Attention</em>, <em class="sig-param">activation: allennlp.nn.activations.Activation = ReLU()</em>, <em class="sig-param">add_action_bias: bool = True</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">num_layers: int = 1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/basic_transition_function.py#L16-L321"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.state_machines.transition_functions.transition_function.TransitionFunction" title="allennlp.state_machines.transition_functions.transition_function.TransitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.state_machines.transition_functions.transition_function.TransitionFunction</span></code></a></p>
<p>This is a typical transition function for a state-based decoder.  We use an LSTM to track
decoder state, and at every timestep we compute an attention over the input question/utterance
to help in selecting the action.  All actions have an embedding, and we use a dot product
between a predicted action embedding and the allowed actions to compute a distribution over
actions at each timestep.</p>
<p>We allow the first action to be predicted separately from everything else.  This is optional,
and is because that’s how the original WikiTableQuestions semantic parser was written.  The
intuition is that maybe you want to predict the type of your output program outside of the
typical LSTM decoder (or maybe Jayant just didn’t realize this could be treated as another
action…).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>encoder_output_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>action_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>input_attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code></span></dt><dd></dd>
<dt><strong>activation</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Activation</span></code>, optional (default=relu)</span></dt><dd><p>The activation that gets applied to the decoder LSTM input and to the action query.</p>
</dd>
<dt><strong>add_action_bias</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=True)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, there has been a bias dimension added to the embedding of each action, which
gets used when predicting the next action.  We add a dimension of ones to our predicted
action vector in this case to account for that.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code> (optional, default=0.0)</span></dt><dd></dd>
<dt><strong>num_layers: ``int``, (optional, default=1)</strong></dt><dd><p>The number of layers in the decoder LSTM.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question">
<code class="sig-name descname">attend_on_question</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">encoder_outputs: torch.Tensor</em>, <em class="sig-param">encoder_output_mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/basic_transition_function.py#L302-L321"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.attend_on_question" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a query (which is typically the decoder hidden state), compute an attention over the
output of the question encoder, and return a weighted sum of the question representations
given this attention.  We also return the attention weights themselves.</p>
<p>This is a simple computation, but we have it as a separate method so that the <code class="docutils literal notranslate"><span class="pre">forward</span></code>
method on the main parser module can call it on the initial hidden state, to simplify the
logic in <code class="docutils literal notranslate"><span class="pre">take_step</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.take_step">
<code class="sig-name descname">take_step</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">state: allennlp.state_machines.states.grammar_based_state.GrammarBasedState</em>, <em class="sig-param">max_actions: int = None</em>, <em class="sig-param">allowed_actions: List[Set[int]] = None</em><span class="sig-paren">)</span> &#x2192; List[allennlp.state_machines.states.grammar_based_state.GrammarBasedState]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/basic_transition_function.py#L83-L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction.take_step" title="Permalink to this definition">¶</a></dt>
<dd><p>The main method in the <code class="docutils literal notranslate"><span class="pre">TransitionFunction</span></code> API.  This function defines the computation
done at each step of decoding and returns a ranked list of next states.</p>
<p>The input state is <cite>grouped</cite>, to allow for efficient computation, but the output states
should all have a <code class="docutils literal notranslate"><span class="pre">group_size</span></code> of 1, to make things easier on the decoding algorithm.
They will get regrouped later as needed.</p>
<p>Because of the way we handle grouping in the decoder states, constructing a new state is
actually a relatively expensive operation.  If you know a priori that only some of the
states will be needed (either because you have a set of gold action sequences, or you have
a fixed beam size), passing that information into this function will keep us from
constructing more states than we need, which will greatly speed up your computation.</p>
<p>IMPORTANT: This method <cite>must</cite> returns states already sorted by their score, otherwise
<code class="docutils literal notranslate"><span class="pre">BeamSearch</span></code> and other methods will break.  For efficiency, we do not perform an
additional sort in those methods.</p>
<p>ALSO IMPORTANT: When <code class="docutils literal notranslate"><span class="pre">allowed_actions</span></code> is given and <code class="docutils literal notranslate"><span class="pre">max_actions</span></code> is not, we assume you
want to evaluate all possible states and do not need any sorting (e.g., this is true for
maximum marginal likelihood training that does not use a beam search).  In this case, we
may skip the sorting step for efficiency reasons.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>state</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">State</span></code></span></dt><dd><p>The current state of the decoder, which we will take a step <cite>from</cite>.  We may be grouping
together computation for several states here.  Because we can have several states for
each instance in the original batch being evaluated at the same time, we use
<code class="docutils literal notranslate"><span class="pre">group_size</span></code> for this kind of batching, and <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> for the <cite>original</cite> batch
in <code class="docutils literal notranslate"><span class="pre">model.forward.</span></code></p>
</dd>
<dt><strong>max_actions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional</span></dt><dd><p>If you know that you will only need a certain number of states out of this (e.g., in a
beam search), you can pass in the max number of actions that you need, and we will only
construct that many states (for each <cite>batch</cite> instance - <cite>not</cite> for each <cite>group</cite>
instance!).  This can save a whole lot of computation if you have an action space
that’s much larger than your beam size.</p>
</dd>
<dt><strong>allowed_actions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Set]</span></code>, optional</span></dt><dd><p>If the <code class="docutils literal notranslate"><span class="pre">DecoderTrainer</span></code> has constraints on which actions need to be evaluated (e.g.,
maximum marginal likelihood only needs to evaluate action sequences in a given set),
you can pass those constraints here, to avoid constructing state objects unnecessarily.
If there are no constraints from the trainer, passing a value of <code class="docutils literal notranslate"><span class="pre">None</span></code> here will
allow all actions to be considered.</p>
<p>This is a list because it is <cite>batched</cite> - every instance in the batch has a set of
allowed actions.  Note that the size of this list is the <code class="docutils literal notranslate"><span class="pre">group_size</span></code> in the
<code class="docutils literal notranslate"><span class="pre">State</span></code>, <cite>not</cite> the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> of <code class="docutils literal notranslate"><span class="pre">model.forward</span></code>.  The training algorithm needs
to convert from the <cite>batched</cite> allowed action sequences that it has to a <cite>grouped</cite>
allowed action sequence list.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>next_states</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[State]</span></code></span></dt><dd><p>A list of next states, ordered by score.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.state_machines.transition_functions.linking_transition_function"></span><dl class="class">
<dt id="allennlp.state_machines.transition_functions.linking_transition_function.LinkingTransitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.state_machines.transition_functions.linking_transition_function.</code><code class="sig-name descname">LinkingTransitionFunction</code><span class="sig-paren">(</span><em class="sig-param">encoder_output_dim: int</em>, <em class="sig-param">action_embedding_dim: int</em>, <em class="sig-param">input_attention: allennlp.modules.attention.attention.Attention</em>, <em class="sig-param">activation: allennlp.nn.activations.Activation = ReLU()</em>, <em class="sig-param">add_action_bias: bool = True</em>, <em class="sig-param">mixture_feedforward: allennlp.modules.feedforward.FeedForward = None</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">num_layers: int = 1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/linking_transition_function.py#L15-L155"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.linking_transition_function.LinkingTransitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction" title="allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction</span></code></a></p>
<p>This transition function adds the ability to consider <cite>linked</cite> actions to the
<code class="docutils literal notranslate"><span class="pre">BasicTransitionFunction</span></code> (which is just an LSTM decoder with attention).  These actions are
potentially unseen at training time, so we need to handle them without requiring the action to
have an embedding.  Instead, we rely on a <cite>linking score</cite> between each action and the words in
the question/utterance, and use these scores, along with the attention, to do something similar
to a copy mechanism when producing these actions.</p>
<p>When both linked and global (embedded) actions are available, we need some way to compare the
scores for these two sets of actions.  The original WikiTableQuestion semantic parser just
concatenated the logits together before doing a joint softmax, but this is quite brittle,
because the logits might have quite different scales.  So we have the option here of predicting
a mixture probability between two independently normalized distributions.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>encoder_output_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>action_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>input_attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code></span></dt><dd></dd>
<dt><strong>activation</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Activation</span></code>, optional (default=relu)</span></dt><dd><p>The activation that gets applied to the decoder LSTM input and to the action query.</p>
</dd>
<dt><strong>add_action_bias</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=True)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, there has been a bias dimension added to the embedding of each action, which
gets used when predicting the next action.  We add a dimension of ones to our predicted
action vector in this case to account for that.</p>
</dd>
<dt><strong>mixture_feedforward</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">FeedForward</span></code> optional (default=None)</span></dt><dd><p>If given, we’ll use this to compute a mixture probability between global actions and linked
actions given the hidden state at every timestep of decoding, instead of concatenating the
logits for both (where the logits may not be compatible with each other).</p>
</dd>
<dt><strong>dropout</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code> (optional, default=0.0)</span></dt><dd></dd>
<dt><strong>num_layers: ``int`` (optional, default=1)</strong></dt><dd><p>The number of layers in the decoder LSTM.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-allennlp.state_machines.transition_functions.coverage_transition_function"></span><dl class="class">
<dt id="allennlp.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.state_machines.transition_functions.coverage_transition_function.</code><code class="sig-name descname">CoverageTransitionFunction</code><span class="sig-paren">(</span><em class="sig-param">encoder_output_dim: int</em>, <em class="sig-param">action_embedding_dim: int</em>, <em class="sig-param">input_attention: allennlp.modules.attention.attention.Attention</em>, <em class="sig-param">activation: allennlp.nn.activations.Activation = ReLU()</em>, <em class="sig-param">add_action_bias: bool = True</em>, <em class="sig-param">dropout: float = 0.0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/coverage_transition_function.py#L15-L148"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction" title="allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.state_machines.transition_functions.basic_transition_function.BasicTransitionFunction</span></code></a></p>
<p>Adds a coverage penalty to the <code class="docutils literal notranslate"><span class="pre">BasicTransitionFunction</span></code> (which is just an LSTM decoder with
attention).  This coverage penalty is on the <cite>output action sequence</cite>, and requires an
externally-computed <cite>agenda</cite> of actions that are expected to be produced during decoding, and
encourages the model to select actions on that agenda.</p>
<p>The way that we encourage the model to select actions on the agenda is that we add the
embeddings for actions on the agenda (that are available at this decoding step and haven’t yet
been taken) to the predicted action embedding.  We weight that addition by a learned multiplier
that gets initialized to 1.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>encoder_output_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>action_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>input_attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code></span></dt><dd></dd>
<dt><strong>activation</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Activation</span></code>, optional (default=relu)</span></dt><dd><p>The activation that gets applied to the decoder LSTM input and to the action query.</p>
</dd>
<dt><strong>add_action_bias</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=True)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, there has been a bias dimension added to the embedding of each action, which
gets used when predicting the next action.  We add a dimension of ones to our predicted
action vector in this case to account for that.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code> (optional, default=0.0)</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-allennlp.state_machines.transition_functions.linking_coverage_transition_function"></span><dl class="class">
<dt id="allennlp.state_machines.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.state_machines.transition_functions.linking_coverage_transition_function.</code><code class="sig-name descname">LinkingCoverageTransitionFunction</code><span class="sig-paren">(</span><em class="sig-param">encoder_output_dim: int</em>, <em class="sig-param">action_embedding_dim: int</em>, <em class="sig-param">input_attention: allennlp.modules.attention.attention.Attention</em>, <em class="sig-param">activation: allennlp.nn.activations.Activation = ReLU()</em>, <em class="sig-param">add_action_bias: bool = True</em>, <em class="sig-param">mixture_feedforward: allennlp.modules.feedforward.FeedForward = None</em>, <em class="sig-param">dropout: float = 0.0</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/state_machines/transition_functions/linking_coverage_transition_function.py#L16-L197"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.state_machines.transition_functions.linking_coverage_transition_function.LinkingCoverageTransitionFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction" title="allennlp.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.state_machines.transition_functions.coverage_transition_function.CoverageTransitionFunction</span></code></a></p>
<p>Combines both linking and coverage on top of the <code class="docutils literal notranslate"><span class="pre">BasicTransitionFunction</span></code> (which is just an
LSTM decoder with attention).  This adds the ability to consider <cite>linked</cite> actions in addition
to global (embedded) actions, and it adds a coverage penalty over the <cite>output action sequence</cite>,
combining the <code class="xref py py-class docutils literal notranslate"><span class="pre">LinkingTransitionFunction</span></code> with the <code class="xref py py-class docutils literal notranslate"><span class="pre">CoverageTransitionFunction</span></code>.</p>
<p>The one thing that’s unique to this class is how the coverage penalty interacts with linked
actions.  Instead of boosting the action’s embedding, as we do in the
<code class="docutils literal notranslate"><span class="pre">CoverageTransitionFunction</span></code>, we boost the action’s logit directly (as there is no action
embedding for linked actions).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>encoder_output_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>action_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd></dd>
<dt><strong>input_attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code></span></dt><dd></dd>
<dt><strong>activation</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Activation</span></code>, optional (default=relu)</span></dt><dd><p>The activation that gets applied to the decoder LSTM input and to the action query.</p>
</dd>
<dt><strong>add_action_bias</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=True)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, there has been a bias dimension added to the embedding of each action, which
gets used when predicting the next action.  We add a dimension of ones to our predicted
action vector in this case to account for that.</p>
</dd>
<dt><strong>dropout</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code> (optional, default=0.0)</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.tools.html" class="btn btn-neutral float-right" title="allennlp.tools" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.state_machines.trainers.html" class="btn btn-neutral float-left" title="allennlp.state_machines.trainers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Allen Institute for Artificial Intelligence

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>