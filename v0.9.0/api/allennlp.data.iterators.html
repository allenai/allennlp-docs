

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.data.iterators &mdash; AllenNLP 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="allennlp.data.token_indexers" href="allennlp.data.token_indexers.html" />
    <link rel="prev" title="allennlp.data.instance" href="allennlp.data.instance.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.configure.html">allennlp.commands.configure</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.make_vocab.html">allennlp.commands.make_vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.fine_tune.html">allennlp.commands.fine_tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.elmo.html">allennlp.commands.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.dry_run.html">allennlp.commands.dry_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.find_learning_rate.html">allennlp.commands.find_learning_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.test_install.html">allennlp.commands.test_install</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.print_results.html">allennlp.commands.print_results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.configuration.html">allennlp.common.configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.from_params.html">allennlp.common.from_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tqdm.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_utils.html">allennlp.data.dataset_readers.dataset_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.babi.html">allennlp.data.dataset_readers.babi</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ccgbank.html">allennlp.data.dataset_readers.ccgbank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2000.html">allennlp.data.dataset_readers.conll2000</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.event2mind.html">allennlp.data.dataset_readers.event2mind</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.interleaving_dataset_reader.html">allennlp.data.dataset_readers.interleaving_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.masked_language_modeling.html">allennlp.data.dataset_readers.masked_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.multiprocess_dataset_reader.html">allennlp.data.dataset_readers.multiprocess_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.next_token_lm.html">allennlp.data.dataset_readers.next_token_lm</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ontonotes_ner.html">allennlp.data.dataset_readers.ontonotes_ner</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.penn_tree_bank.html">allennlp.data.dataset_readers.penn_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_dependency_parsing.html">allennlp.data.dataset_readers.semantic_dependency_parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.html">allennlp.data.dataset_readers.semantic_parsing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.wikitables.html">allennlp.data.dataset_readers.semantic_parsing.wikitables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.simple_language_modeling.html">allennlp.data.dataset_readers.simple_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.stanford_sentiment_tree_bank.html">allennlp.data.dataset_readers.stanford_sentiment_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies.html">allennlp.data.dataset_readers.universal_dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies_multilang.html">allennlp.data.dataset_readers.universal_dependencies_multilang</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.copynet_seq2seq.html">allennlp.data.dataset_readers.copynet_seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.text_classification_json.html">allennlp.data.dataset_readers.text_classification_json</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.interpret.html">allennlp.interpret</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.attackers.html">allennlp.interpret.attackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.saliency_interpreters.html">allennlp.interpret.saliency_interpreters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.basic_classifier.html">allennlp.models.basic_classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bert_for_classification.html">allennlp.models.bert_for_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser.html">allennlp.models.biaffine_dependency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser_multilang.html">allennlp.models.biaffine_dependency_parser_multilang</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biattentive_classification_network.html">allennlp.models.biattentive_classification_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bimpm.html">allennlp.models.bimpm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.constituency_parser.html">allennlp.models.constituency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.ensemble.html">allennlp.models.ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.esim.html">allennlp.models.esim</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.event2mind.html">allennlp.models.event2mind</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.graph_parser.html">allennlp.models.graph_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.language_model.html">allennlp.models.language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.masked_language_model.html">allennlp.models.masked_language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.next_token_lm.html">allennlp.models.next_token_lm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_parsing.html">allennlp.models.semantic_parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.nlvr.html">allennlp.models.semantic_parsing.nlvr</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.wikitables.html">allennlp.models.semantic_parsing.wikitables</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.atis.html">allennlp.models.semantic_parsing.atis</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.quarel.html">allennlp.models.semantic_parsing.quarel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_bert.html">allennlp.models.srl_bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_util.html">allennlp.models.srl_util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.predictors.html">allennlp.predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo.html">allennlp.modules.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.language_model_heads.html">allennlp.modules.language_model_heads</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.openai_transformer.html">allennlp.modules.openai_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_decoders.html">allennlp.modules.seq2seq_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.span_extractors.html">allennlp.modules.span_extractors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_bidirectional_lstm.html">allennlp.modules.stacked_bidirectional_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.layer_norm.html">allennlp.modules.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.pruner.html">allennlp.modules.pruner</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.maxout.html">allennlp.modules.maxout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.input_variational_dropout.html">allennlp.modules.input_variational_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.bimpm_matching.html">allennlp.modules.bimpm_matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.masked_layer_norm.html">allennlp.modules.masked_layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.sampled_softmax_loss.html">allennlp.modules.sampled_softmax_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.residual_with_layer_dropout.html">allennlp.modules.residual_with_layer_dropout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.chu_liu_edmonds.html">allennlp.nn.chu_liu_edmonds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.beam_search.html">allennlp.nn.beam_search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.semparse.html">allennlp.semparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.common.html">allennlp.semparse.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.contexts.html">allennlp.semparse.contexts</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.type_declarations.html">allennlp.semparse.type_declarations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.worlds.html">allennlp.semparse.worlds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.domain_languages.html">allennlp.semparse.domain_languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.util.html">allennlp.semparse.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_simple.html">allennlp.service.server_simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.config_explorer.html">allennlp.service.config_explorer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.state_machines.html">allennlp.state_machines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.states.html">allennlp.state_machines.states</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.trainers.html">allennlp.state_machines.trainers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.transition_functions.html">allennlp.state_machines.transition_functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.tools.html">allennlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callbacks.html">allennlp.training.callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callback_trainer.html">allennlp.training.callback_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.checkpointer.html">allennlp.training.checkpointer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.scheduler.html">allennlp.training.scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.momentum_schedulers.html">allennlp.training.momentum_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metric_tracker.html">allennlp.training.metric_tracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.moving_average.html">allennlp.training.moving_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.no_op_trainer.html">allennlp.training.no_op_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.tensorboard_writer.html">allennlp.training.tensorboard_writer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_base.html">allennlp.training.trainer_base</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_pieces.html">allennlp.training.trainer_pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.util.html">allennlp.training.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.pretrained.html">allennlp.pretrained</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.data.html">allennlp.data</a> &raquo;</li>
        
      <li>allennlp.data.iterators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.data.iterators.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.data.iterators">
<span id="allennlp-data-iterators"></span><h1>allennlp.data.iterators<a class="headerlink" href="#module-allennlp.data.iterators" title="Permalink to this headline">¶</a></h1>
<p>The various <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataIterator</span></code></a> subclasses
can be used to iterate over datasets with different batching and padding schemes.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#data-iterator"><span class="std std-ref">DataIterator</span></a></p></li>
<li><p><a class="reference internal" href="#basic-iterator"><span class="std std-ref">BasicIterator</span></a></p></li>
<li><p><a class="reference internal" href="#bucket-iterator"><span class="std std-ref">BucketIterator</span></a></p></li>
<li><p><a class="reference internal" href="#multiprocess-iterator"><span class="std std-ref">MultiprocessIterator</span></a></p></li>
<li><p><a class="reference internal" href="#homogeneous-batch-iterator"><span class="std std-ref">HomogeneousBatchIterator</span></a></p></li>
<li><p><a class="reference internal" href="#same-language-iterator"><span class="std std-ref">SameLanguageIterator</span></a></p></li>
<li><p><a class="reference internal" href="#pass-through-iterator"><span class="std std-ref">PassThroughIterator</span></a></p></li>
</ul>
<span class="target" id="module-allennlp.data.iterators.data_iterator"><span id="data-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.data_iterator.DataIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.data_iterator.</code><code class="sig-name descname">DataIterator</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int = 32</em>, <em class="sig-param">instances_per_epoch: int = None</em>, <em class="sig-param">max_instances_in_memory: int = None</em>, <em class="sig-param">cache_instances: bool = False</em>, <em class="sig-param">track_epoch: bool = False</em>, <em class="sig-param">maximum_samples_per_batch: Tuple[str</em>, <em class="sig-param">int] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/data_iterator.py#L31-L321"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.data_iterator.DataIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>An abstract <code class="docutils literal notranslate"><span class="pre">DataIterator</span></code> class. <code class="docutils literal notranslate"><span class="pre">DataIterators</span></code> must override <code class="docutils literal notranslate"><span class="pre">_create_batches()</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>batch_size</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = 32)</span></dt><dd><p>The size of each batch of instances yielded when calling the iterator.</p>
</dd>
<dt><strong>instances_per_epoch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = None)</span></dt><dd><p>If specified, each epoch will consist of precisely this many instances.
If not specified, each epoch will consist of a single pass through the dataset.</p>
</dd>
<dt><strong>max_instances_in_memory</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = None)</span></dt><dd><p>If specified, the iterator will load this many instances at a time into an
in-memory list and then produce batches from one such list at a time. This
could be useful if your instances are read lazily from disk.</p>
</dd>
<dt><strong>cache_instances</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional, (default = False)</span></dt><dd><p>If true, the iterator will cache the tensorized instances in memory.
If false, it will do the tensorization anew each iteration.</p>
</dd>
<dt><strong>track_epoch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional, (default = False)</span></dt><dd><p>If true, each instance will get a <code class="docutils literal notranslate"><span class="pre">MetadataField</span></code> containing the epoch number.</p>
</dd>
<dt><strong>maximum_samples_per_batch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">int]</span></code>, (default = None)</span></dt><dd><p>If specified, then is a tuple (padding_key, limit) and we will ensure
that every batch is such that batch_size * sequence_length &lt;= limit
where sequence_length is given by the padding_key. This is done by
moving excess instances to the next batch (as opposed to dividing a
large batch evenly) and should result in a fairly tight packing.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="attribute">
<dt id="allennlp.data.iterators.data_iterator.DataIterator.default_implementation">
<code class="sig-name descname">default_implementation</code><em class="property">: str</em><em class="property"> = 'bucket'</em><a class="headerlink" href="#allennlp.data.iterators.data_iterator.DataIterator.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.iterators.data_iterator.DataIterator.get_num_batches">
<code class="sig-name descname">get_num_batches</code><span class="sig-paren">(</span><em class="sig-param">self, instances: Iterable[allennlp.data.instance.Instance]</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/data_iterator.py#L299-L312"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.data_iterator.DataIterator.get_num_batches" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of batches that <code class="docutils literal notranslate"><span class="pre">dataset</span></code> will be split into; if you want to track
progress through the batch with the generator produced by <code class="docutils literal notranslate"><span class="pre">__call__</span></code>, this could be
useful.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.iterators.data_iterator.DataIterator.index_with">
<code class="sig-name descname">index_with</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/data_iterator.py#L320-L321"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.data_iterator.DataIterator.index_with" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="allennlp.data.iterators.data_iterator.add_epoch_number">
<code class="sig-prename descclassname">allennlp.data.iterators.data_iterator.</code><code class="sig-name descname">add_epoch_number</code><span class="sig-paren">(</span><em class="sig-param">batch: allennlp.data.dataset.Batch</em>, <em class="sig-param">epoch: int</em><span class="sig-paren">)</span> &#x2192; allennlp.data.dataset.Batch<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/data_iterator.py#L22-L28"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.data_iterator.add_epoch_number" title="Permalink to this definition">¶</a></dt>
<dd><p>Add the epoch number to the batch instances as a MetadataField.</p>
</dd></dl>

<span class="target" id="module-allennlp.data.iterators.basic_iterator"><span id="basic-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.basic_iterator.BasicIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.basic_iterator.</code><code class="sig-name descname">BasicIterator</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int = 32</em>, <em class="sig-param">instances_per_epoch: int = None</em>, <em class="sig-param">max_instances_in_memory: int = None</em>, <em class="sig-param">cache_instances: bool = False</em>, <em class="sig-param">track_epoch: bool = False</em>, <em class="sig-param">maximum_samples_per_batch: Tuple[str</em>, <em class="sig-param">int] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/basic_iterator.py#L15-L34"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.basic_iterator.BasicIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.data_iterator.DataIterator</span></code></a></p>
<p>A very basic iterator that takes a dataset, possibly shuffles it, and creates fixed sized batches.</p>
<p>It takes the same parameters as <code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.DataIterator</span></code></p>
</dd></dl>

<span class="target" id="module-allennlp.data.iterators.bucket_iterator"><span id="bucket-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.bucket_iterator.BucketIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.bucket_iterator.</code><code class="sig-name descname">BucketIterator</code><span class="sig-paren">(</span><em class="sig-param">sorting_keys: List[Tuple[str, str]], padding_noise: float = 0.1, biggest_batch_first: bool = False, batch_size: int = 32, instances_per_epoch: int = None, max_instances_in_memory: int = None, cache_instances: bool = False, track_epoch: bool = False, maximum_samples_per_batch: Tuple[str, int] = None, skip_smaller_batches: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/bucket_iterator.py#L46-L152"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.bucket_iterator.BucketIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.data_iterator.DataIterator</span></code></a></p>
<p>An iterator which by default, pads batches with respect to the maximum input lengths <cite>per
batch</cite>. Additionally, you can provide a list of field names and padding keys which the dataset
will be sorted by before doing this batching, causing inputs with similar length to be batched
together, making computation more efficient (as less time is wasted on padded elements of the
batch).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>sorting_keys</strong><span class="classifier">List[Tuple[str, str]]</span></dt><dd><p>To bucket inputs into batches, we want to group the instances by padding length, so that we
minimize the amount of padding necessary per batch. In order to do this, we need to know
which fields need what type of padding, and in what order.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">[(&quot;sentence1&quot;,</span> <span class="pre">&quot;num_tokens&quot;),</span> <span class="pre">(&quot;sentence2&quot;,</span> <span class="pre">&quot;num_tokens&quot;),</span> <span class="pre">(&quot;sentence1&quot;,</span>
<span class="pre">&quot;num_token_characters&quot;)]</span></code> would sort a dataset first by the “num_tokens” of the
“sentence1” field, then by the “num_tokens” of the “sentence2” field, and finally by the
“num_token_characters” of the “sentence1” field.  TODO(mattg): we should have some
documentation somewhere that gives the standard padding keys used by different fields.</p>
</dd>
<dt><strong>padding_noise</strong><span class="classifier">float, optional (default=.1)</span></dt><dd><p>When sorting by padding length, we add a bit of noise to the lengths, so that the sorting
isn’t deterministic.  This parameter determines how much noise we add, as a percentage of
the actual padding value for each instance.</p>
</dd>
<dt><strong>biggest_batch_first</strong><span class="classifier">bool, optional (default=False)</span></dt><dd><p>This is largely for testing, to see how large of a batch you can safely use with your GPU.
This will let you try out the largest batch that you have in the data <cite>first</cite>, so that if
you’re going to run out of memory, you know it early, instead of waiting through the whole
epoch to find out at the end that you’re going to crash.</p>
<p>Note that if you specify <code class="docutils literal notranslate"><span class="pre">max_instances_in_memory</span></code>, the first batch will only be the
biggest from among the first “max instances in memory” instances.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional, (default = 32)</span></dt><dd><p>The size of each batch of instances yielded when calling the iterator.</p>
</dd>
<dt><strong>instances_per_epoch</strong><span class="classifier">int, optional, (default = None)</span></dt><dd><p>See <code class="xref py py-class docutils literal notranslate"><span class="pre">BasicIterator</span></code>.</p>
</dd>
<dt><strong>max_instances_in_memory</strong><span class="classifier">int, optional, (default = None)</span></dt><dd><p>See <code class="xref py py-class docutils literal notranslate"><span class="pre">BasicIterator</span></code>.</p>
</dd>
<dt><strong>maximum_samples_per_batch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">int]</span></code>, (default = None)</span></dt><dd><p>See <code class="xref py py-class docutils literal notranslate"><span class="pre">BasicIterator</span></code>.</p>
</dd>
<dt><strong>skip_smaller_batches</strong><span class="classifier">bool, optional, (default = False)</span></dt><dd><p>When the number of data samples is not dividable by <cite>batch_size</cite>,
some batches might be smaller than <cite>batch_size</cite>.
If set to <cite>True</cite>, those smaller batches will be discarded.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="allennlp.data.iterators.bucket_iterator.sort_by_padding">
<code class="sig-prename descclassname">allennlp.data.iterators.bucket_iterator.</code><code class="sig-name descname">sort_by_padding</code><span class="sig-paren">(</span><em class="sig-param">instances: List[allennlp.data.instance.Instance], sorting_keys: List[Tuple[str, str]], vocab: allennlp.data.vocabulary.Vocabulary, padding_noise: float = 0.0</em><span class="sig-paren">)</span> &#x2192; List[allennlp.data.instance.Instance]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/bucket_iterator.py#L18-L42"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.bucket_iterator.sort_by_padding" title="Permalink to this definition">¶</a></dt>
<dd><p>Sorts the instances by their padding lengths, using the keys in
<code class="docutils literal notranslate"><span class="pre">sorting_keys</span></code> (in the order in which they are provided).  <code class="docutils literal notranslate"><span class="pre">sorting_keys</span></code> is a list of
<code class="docutils literal notranslate"><span class="pre">(field_name,</span> <span class="pre">padding_key)</span></code> tuples.</p>
</dd></dl>

<span class="target" id="module-allennlp.data.iterators.multiprocess_iterator"><span id="multiprocess-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.multiprocess_iterator.MultiprocessIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.multiprocess_iterator.</code><code class="sig-name descname">MultiprocessIterator</code><span class="sig-paren">(</span><em class="sig-param">base_iterator: allennlp.data.iterators.data_iterator.DataIterator</em>, <em class="sig-param">num_workers: int = 1</em>, <em class="sig-param">output_queue_size: int = 1000</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/multiprocess_iterator.py#L97-L245"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.multiprocess_iterator.MultiprocessIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.data_iterator.DataIterator</span></code></a></p>
<p>Wraps another <code class="docutils literal notranslate"><span class="pre">`DataIterator`</span></code> and uses it to generate tensor dicts
using multiple processes.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>base_iterator</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">DataIterator</span></code></span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">DataIterator</span></code> for generating tensor dicts. It will be shared among
processes, so it should not be stateful in any way.</p>
</dd>
<dt><strong>num_workers</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default = 1)</span></dt><dd><p>The number of processes used for generating tensor dicts.</p>
</dd>
<dt><strong>output_queue_size: ``int``, optional (default = 1000)</strong></dt><dd><p>The size of the output queue on which tensor dicts are placed to be consumed.
You might need to increase this if you’re generating tensor dicts too quickly.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.iterators.multiprocess_iterator.MultiprocessIterator.index_with">
<code class="sig-name descname">index_with</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/multiprocess_iterator.py#L138-L139"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.multiprocess_iterator.MultiprocessIterator.index_with" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.iterators.homogeneous_batch_iterator"><span id="homogeneous-batch-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.homogeneous_batch_iterator.HomogeneousBatchIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.homogeneous_batch_iterator.</code><code class="sig-name descname">HomogeneousBatchIterator</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int = 32</em>, <em class="sig-param">instances_per_epoch: int = None</em>, <em class="sig-param">max_instances_in_memory: int = None</em>, <em class="sig-param">cache_instances: bool = False</em>, <em class="sig-param">track_epoch: bool = False</em>, <em class="sig-param">partition_key: str = 'dataset'</em>, <em class="sig-param">skip_smaller_batches: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/homogeneous_batch_iterator.py#L12-L83"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.homogeneous_batch_iterator.HomogeneousBatchIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.data_iterator.DataIterator</span></code></a></p>
<p>This iterator takes a dataset of potentially heterogeneous instances
and yields back homogeneous batches. It assumes that each instance has
some <code class="docutils literal notranslate"><span class="pre">MetadataField</span></code> indicating what “type” of instance it is
and bases its notion of homogeneity on that (and, in particular, not on
inspecting the “field signature” of the instance.)</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>batch_size</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = 32)</span></dt><dd><p>The size of each batch of instances yielded when calling the iterator.</p>
</dd>
<dt><strong>instances_per_epoch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = None)</span></dt><dd><p>If specified, each epoch will consist of precisely this many instances.
If not specified, each epoch will consist of a single pass through the dataset.</p>
</dd>
<dt><strong>max_instances_in_memory</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional, (default = None)</span></dt><dd><p>If specified, the iterator will load this many instances at a time into an
in-memory list and then produce batches from one such list at a time. This
could be useful if your instances are read lazily from disk.</p>
</dd>
<dt><strong>cache_instances</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional, (default = False)</span></dt><dd><p>If true, the iterator will cache the tensorized instances in memory.
If false, it will do the tensorization anew each iteration.</p>
</dd>
<dt><strong>track_epoch</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional, (default = False)</span></dt><dd><p>If true, each instance will get a <code class="docutils literal notranslate"><span class="pre">MetadataField</span></code> containing the epoch number.</p>
</dd>
<dt><strong>partition_key</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional, (default = “dataset”)</span></dt><dd><p>The key of the <code class="docutils literal notranslate"><span class="pre">MetadataField</span></code> indicating what “type” of instance this is.</p>
</dd>
<dt><strong>skip_smaller_batches</strong><span class="classifier">bool, optional, (default = False)</span></dt><dd><p>When the number of data samples is not dividable by <cite>batch_size</cite>,
some batches might be smaller than <cite>batch_size</cite>.
If set to <cite>True</cite>, those smaller batches will be discarded.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-allennlp.data.iterators.same_language_iterator"><span id="same-language-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.same_language_iterator.SameLanguageIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.same_language_iterator.</code><code class="sig-name descname">SameLanguageIterator</code><span class="sig-paren">(</span><em class="sig-param">sorting_keys: List[Tuple[str, str]], padding_noise: float = 0.1, biggest_batch_first: bool = False, batch_size: int = 32, instances_per_epoch: int = None, max_instances_in_memory: int = None, cache_instances: bool = False, track_epoch: bool = False, maximum_samples_per_batch: Tuple[str, int] = None, skip_smaller_batches: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/same_language_iterator.py#L23-L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.same_language_iterator.SameLanguageIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.bucket_iterator.BucketIterator" title="allennlp.data.iterators.bucket_iterator.BucketIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.bucket_iterator.BucketIterator</span></code></a></p>
<p>Splits batches into batches containing the same language.
The language of each instance is determined by looking at the ‘lang’ value
in the metadata.</p>
<p>It takes the same parameters as <code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.BucketIterator</span></code></p>
</dd></dl>

<dl class="function">
<dt id="allennlp.data.iterators.same_language_iterator.split_by_language">
<code class="sig-prename descclassname">allennlp.data.iterators.same_language_iterator.</code><code class="sig-name descname">split_by_language</code><span class="sig-paren">(</span><em class="sig-param">instance_list</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/same_language_iterator.py#L14-L20"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.same_language_iterator.split_by_language" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<span class="target" id="module-allennlp.data.iterators.pass_through_iterator"><span id="pass-through-iterator"></span></span><dl class="class">
<dt id="allennlp.data.iterators.pass_through_iterator.PassThroughIterator">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.iterators.pass_through_iterator.</code><code class="sig-name descname">PassThroughIterator</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/iterators/pass_through_iterator.py#L15-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.iterators.pass_through_iterator.PassThroughIterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.iterators.data_iterator.DataIterator" title="allennlp.data.iterators.data_iterator.DataIterator"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.iterators.data_iterator.DataIterator</span></code></a></p>
<p>An iterator which performs no batching or shuffling of instances, only tensorization. E.g,
instances are effectively passed ‘straight through’ the iterator.</p>
<p>This is essentially the same as a BasicIterator with shuffling disabled, the batch size set
to 1, and maximum samples per batch disabled. The only difference is that this iterator
removes the batch dimension. This can be useful for rare situations where batching is best
performed within the dataset reader (e.g. for contiguous language modeling, or for other
problems where state is shared across batches).</p>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.data.token_indexers.html" class="btn btn-neutral float-right" title="allennlp.data.token_indexers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.data.instance.html" class="btn btn-neutral float-left" title="allennlp.data.instance" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Allen Institute for Artificial Intelligence

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>