

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.modules.text_field_embedders &mdash; AllenNLP 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="allennlp.modules.time_distributed" href="allennlp.modules.time_distributed.html" />
    <link rel="prev" title="allennlp.modules.stacked_bidirectional_lstm" href="allennlp.modules.stacked_bidirectional_lstm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.configure.html">allennlp.commands.configure</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.make_vocab.html">allennlp.commands.make_vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.fine_tune.html">allennlp.commands.fine_tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.elmo.html">allennlp.commands.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.dry_run.html">allennlp.commands.dry_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.find_learning_rate.html">allennlp.commands.find_learning_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.test_install.html">allennlp.commands.test_install</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.print_results.html">allennlp.commands.print_results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.configuration.html">allennlp.common.configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.from_params.html">allennlp.common.from_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tqdm.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_utils.html">allennlp.data.dataset_readers.dataset_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.babi.html">allennlp.data.dataset_readers.babi</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ccgbank.html">allennlp.data.dataset_readers.ccgbank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2000.html">allennlp.data.dataset_readers.conll2000</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.event2mind.html">allennlp.data.dataset_readers.event2mind</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.interleaving_dataset_reader.html">allennlp.data.dataset_readers.interleaving_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.masked_language_modeling.html">allennlp.data.dataset_readers.masked_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.multiprocess_dataset_reader.html">allennlp.data.dataset_readers.multiprocess_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.next_token_lm.html">allennlp.data.dataset_readers.next_token_lm</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ontonotes_ner.html">allennlp.data.dataset_readers.ontonotes_ner</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.penn_tree_bank.html">allennlp.data.dataset_readers.penn_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_dependency_parsing.html">allennlp.data.dataset_readers.semantic_dependency_parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.html">allennlp.data.dataset_readers.semantic_parsing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.wikitables.html">allennlp.data.dataset_readers.semantic_parsing.wikitables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.simple_language_modeling.html">allennlp.data.dataset_readers.simple_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.stanford_sentiment_tree_bank.html">allennlp.data.dataset_readers.stanford_sentiment_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies.html">allennlp.data.dataset_readers.universal_dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies_multilang.html">allennlp.data.dataset_readers.universal_dependencies_multilang</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.copynet_seq2seq.html">allennlp.data.dataset_readers.copynet_seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.text_classification_json.html">allennlp.data.dataset_readers.text_classification_json</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.interpret.html">allennlp.interpret</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.attackers.html">allennlp.interpret.attackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.saliency_interpreters.html">allennlp.interpret.saliency_interpreters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.basic_classifier.html">allennlp.models.basic_classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bert_for_classification.html">allennlp.models.bert_for_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser.html">allennlp.models.biaffine_dependency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser_multilang.html">allennlp.models.biaffine_dependency_parser_multilang</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biattentive_classification_network.html">allennlp.models.biattentive_classification_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bimpm.html">allennlp.models.bimpm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.constituency_parser.html">allennlp.models.constituency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.ensemble.html">allennlp.models.ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.esim.html">allennlp.models.esim</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.event2mind.html">allennlp.models.event2mind</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.graph_parser.html">allennlp.models.graph_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.language_model.html">allennlp.models.language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.masked_language_model.html">allennlp.models.masked_language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.next_token_lm.html">allennlp.models.next_token_lm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_parsing.html">allennlp.models.semantic_parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.nlvr.html">allennlp.models.semantic_parsing.nlvr</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.wikitables.html">allennlp.models.semantic_parsing.wikitables</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.atis.html">allennlp.models.semantic_parsing.atis</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.quarel.html">allennlp.models.semantic_parsing.quarel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_bert.html">allennlp.models.srl_bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_util.html">allennlp.models.srl_util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.predictors.html">allennlp.predictors</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo.html">allennlp.modules.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.language_model_heads.html">allennlp.modules.language_model_heads</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.openai_transformer.html">allennlp.modules.openai_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_decoders.html">allennlp.modules.seq2seq_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.span_extractors.html">allennlp.modules.span_extractors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_bidirectional_lstm.html">allennlp.modules.stacked_bidirectional_lstm</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.layer_norm.html">allennlp.modules.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.pruner.html">allennlp.modules.pruner</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.maxout.html">allennlp.modules.maxout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.input_variational_dropout.html">allennlp.modules.input_variational_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.bimpm_matching.html">allennlp.modules.bimpm_matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.masked_layer_norm.html">allennlp.modules.masked_layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.sampled_softmax_loss.html">allennlp.modules.sampled_softmax_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.residual_with_layer_dropout.html">allennlp.modules.residual_with_layer_dropout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.chu_liu_edmonds.html">allennlp.nn.chu_liu_edmonds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.beam_search.html">allennlp.nn.beam_search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.semparse.html">allennlp.semparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.common.html">allennlp.semparse.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.contexts.html">allennlp.semparse.contexts</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.type_declarations.html">allennlp.semparse.type_declarations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.worlds.html">allennlp.semparse.worlds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.domain_languages.html">allennlp.semparse.domain_languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.util.html">allennlp.semparse.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_simple.html">allennlp.service.server_simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.config_explorer.html">allennlp.service.config_explorer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.state_machines.html">allennlp.state_machines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.states.html">allennlp.state_machines.states</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.trainers.html">allennlp.state_machines.trainers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.transition_functions.html">allennlp.state_machines.transition_functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.tools.html">allennlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callbacks.html">allennlp.training.callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callback_trainer.html">allennlp.training.callback_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.checkpointer.html">allennlp.training.checkpointer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.scheduler.html">allennlp.training.scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.momentum_schedulers.html">allennlp.training.momentum_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metric_tracker.html">allennlp.training.metric_tracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.moving_average.html">allennlp.training.moving_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.no_op_trainer.html">allennlp.training.no_op_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.tensorboard_writer.html">allennlp.training.tensorboard_writer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_base.html">allennlp.training.trainer_base</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_pieces.html">allennlp.training.trainer_pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.util.html">allennlp.training.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.pretrained.html">allennlp.pretrained</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.modules.html">allennlp.modules</a> &raquo;</li>
        
      <li>allennlp.modules.text_field_embedders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.modules.text_field_embedders.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.modules.text_field_embedders">
<span id="allennlp-modules-text-field-embedders"></span><h1>allennlp.modules.text_field_embedders<a class="headerlink" href="#module-allennlp.modules.text_field_embedders" title="Permalink to this headline">¶</a></h1>
<p>A <a class="reference internal" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder" title="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder"><code class="xref py py-class docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code></a>
is a <code class="docutils literal notranslate"><span class="pre">Module</span></code> that takes as input the <code class="docutils literal notranslate"><span class="pre">dict</span></code> of NumPy arrays
produced by a <a class="reference internal" href="allennlp.data.fields.html#allennlp.data.fields.text_field.TextField" title="allennlp.data.fields.text_field.TextField"><code class="xref py py-class docutils literal notranslate"><span class="pre">TextField</span></code></a> and
returns as output an embedded representation of the tokens in that field.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#text-field-embedder"><span class="std std-ref">TextFieldEmbedder</span></a></p></li>
<li><p><a class="reference internal" href="#basic-text-field-embedder"><span class="std std-ref">BasicTextFieldEmbedder</span></a></p></li>
</ul>
<span class="target" id="module-allennlp.modules.text_field_embedders.text_field_embedder"><span id="text-field-embedder"></span></span><dl class="class">
<dt id="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.modules.text_field_embedders.text_field_embedder.</code><code class="sig-name descname">TextFieldEmbedder</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/text_field_embedder.py#L7-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code> is a <code class="docutils literal notranslate"><span class="pre">Module</span></code> that takes as input the
<code class="xref py py-class docutils literal notranslate"><span class="pre">DataArray</span></code> produced by a <code class="xref py py-class docutils literal notranslate"><span class="pre">TextField</span></code> and
returns as output an embedded representation of the tokens in that field.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DataArrays</span></code> produced by <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> are <cite>dictionaries</cite> with named representations,
like “words” and “characters”.  When you create a <code class="docutils literal notranslate"><span class="pre">TextField</span></code>, you pass in a dictionary of
<code class="xref py py-class docutils literal notranslate"><span class="pre">TokenIndexer</span></code> objects, telling the field how exactly the tokens in the
field should be represented.  This class changes the type signature of <code class="docutils literal notranslate"><span class="pre">Module.forward</span></code>,
restricting <code class="docutils literal notranslate"><span class="pre">TextFieldEmbedders</span></code> to take inputs corresponding to a single <code class="docutils literal notranslate"><span class="pre">TextField</span></code>,
which is a dictionary of tensors with the same names as were passed to the <code class="docutils literal notranslate"><span class="pre">TextField</span></code>.</p>
<p>We also add a method to the basic <code class="docutils literal notranslate"><span class="pre">Module</span></code> API: <a class="reference internal" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.get_output_dim" title="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.get_output_dim"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_output_dim()</span></code></a>.  You might need
this if you want to construct a <code class="docutils literal notranslate"><span class="pre">Linear</span></code> layer using the output of this embedder, for
instance.</p>
<dl class="attribute">
<dt id="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.default_implementation">
<code class="sig-name descname">default_implementation</code><em class="property">: str</em><em class="property"> = 'basic'</em><a class="headerlink" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">self, text_field_input: Dict[str, torch.Tensor], num_wrapping_dims: int = 0, **kwargs</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/text_field_embedder.py#L26-L43"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>text_field_input</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code></span></dt><dd><p>A dictionary that was the output of a call to <code class="docutils literal notranslate"><span class="pre">TextField.as_tensor</span></code>.  Each tensor in
here is assumed to have a shape roughly similar to <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>
(perhaps with an extra trailing dimension for the characters in each token).</p>
</dd>
<dt><strong>num_wrapping_dims</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default=0)</span></dt><dd><p>If you have a <code class="docutils literal notranslate"><span class="pre">ListField[TextField]</span></code> that created the <code class="docutils literal notranslate"><span class="pre">text_field_input</span></code>, you’ll
end up with tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">wrapping_dim1,</span> <span class="pre">wrapping_dim2,</span> <span class="pre">...,</span>
<span class="pre">sequence_length)</span></code>.  This parameter tells us how many wrapping dimensions there are, so
that we can correctly <code class="docutils literal notranslate"><span class="pre">TimeDistribute</span></code> the embedding of each named representation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.get_output_dim">
<code class="sig-name descname">get_output_dim</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/text_field_embedder.py#L45-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.get_output_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the dimension of the vector representing each token in the output of this
<code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code>.  This is <cite>not</cite> the shape of the returned tensor, but the last element of
that shape.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.modules.text_field_embedders.basic_text_field_embedder"><span id="basic-text-field-embedder"></span></span><dl class="class">
<dt id="allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.modules.text_field_embedders.basic_text_field_embedder.</code><code class="sig-name descname">BasicTextFieldEmbedder</code><span class="sig-paren">(</span><em class="sig-param">token_embedders: Dict[str, allennlp.modules.token_embedders.token_embedder.TokenEmbedder], embedder_to_indexer_map: Dict[str, Union[List[str], Dict[str, str]]] = None, allow_unmatched_keys: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/basic_text_field_embedder.py#L16-L171"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder" title="allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder</span></code></a></p>
<p>This is a <code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code> that wraps a collection of <code class="xref py py-class docutils literal notranslate"><span class="pre">TokenEmbedder</span></code> objects.  Each
<code class="docutils literal notranslate"><span class="pre">TokenEmbedder</span></code> embeds or encodes the representation output from one
<code class="xref py py-class docutils literal notranslate"><span class="pre">TokenIndexer</span></code>.  As the data produced by a
<code class="xref py py-class docutils literal notranslate"><span class="pre">TextField</span></code> is a dictionary mapping names to these
representations, we take <code class="docutils literal notranslate"><span class="pre">TokenEmbedders</span></code> with corresponding names.  Each <code class="docutils literal notranslate"><span class="pre">TokenEmbedders</span></code>
embeds its input, and the result is concatenated in an arbitrary order.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>token_embedders</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">TokenEmbedder]</span></code>, required.</span></dt><dd><p>A dictionary mapping token embedder names to implementations.
These names should match the corresponding indexer used to generate
the tensor passed to the TokenEmbedder.</p>
</dd>
<dt><strong>embedder_to_indexer_map</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Union[List[str],</span> <span class="pre">Dict[str,</span> <span class="pre">str]]]</span></code>, optional, (default = None)</span></dt><dd><p>Optionally, you can provide a mapping between the names of the TokenEmbedders that
you are using to embed your TextField and an ordered list of indexer names which
are needed for running it, or a mapping between the parameters which the
<code class="docutils literal notranslate"><span class="pre">TokenEmbedder.forward</span></code> takes and the indexer names which are viewed as arguments.
In most cases, your TokenEmbedder will only require a single tensor, because it is
designed to run on the output of a single TokenIndexer. For example, the ELMo Token
Embedder can be used in two modes, one of which requires both character ids and word
ids for the same text. Note that the list of token indexer names is <cite>ordered</cite>,
meaning that the tensors produced by the indexers will be passed to the embedders in
the order you specify in this list. You can also use <cite>null</cite> in the configuration to
set some specified parameters to None.</p>
</dd>
<dt><strong>allow_unmatched_keys</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default = False)</span></dt><dd><p>If True, then don’t enforce the keys of the <code class="docutils literal notranslate"><span class="pre">text_field_input</span></code> to
match those in <code class="docutils literal notranslate"><span class="pre">token_embedders</span></code> (useful if the mapping is specified
via <code class="docutils literal notranslate"><span class="pre">embedder_to_indexer_map</span></code>).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">self, text_field_input: Dict[str, torch.Tensor], num_wrapping_dims: int = 0, **kwargs</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/basic_text_field_embedder.py#L68-L133"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>text_field_input</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code></span></dt><dd><p>A dictionary that was the output of a call to <code class="docutils literal notranslate"><span class="pre">TextField.as_tensor</span></code>.  Each tensor in
here is assumed to have a shape roughly similar to <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">sequence_length)</span></code>
(perhaps with an extra trailing dimension for the characters in each token).</p>
</dd>
<dt><strong>num_wrapping_dims</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default=0)</span></dt><dd><p>If you have a <code class="docutils literal notranslate"><span class="pre">ListField[TextField]</span></code> that created the <code class="docutils literal notranslate"><span class="pre">text_field_input</span></code>, you’ll
end up with tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">wrapping_dim1,</span> <span class="pre">wrapping_dim2,</span> <span class="pre">...,</span>
<span class="pre">sequence_length)</span></code>.  This parameter tells us how many wrapping dimensions there are, so
that we can correctly <code class="docutils literal notranslate"><span class="pre">TimeDistribute</span></code> the embedding of each named representation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.from_params">
<em class="property">classmethod </em><code class="sig-name descname">from_params</code><span class="sig-paren">(</span><em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em>, <em class="sig-param">params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; 'BasicTextFieldEmbedder'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/basic_text_field_embedder.py#L136-L171"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.from_params" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the automatic implementation of <cite>from_params</cite>. Any class that subclasses <cite>FromParams</cite>
(or <cite>Registrable</cite>, which itself subclasses <cite>FromParams</cite>) gets this implementation for free.
If you want your class to be instantiated from params in the “obvious” way – pop off parameters
and hand them to your constructor with the same names – this provides that functionality.</p>
<p>If you need more complex logic in your from <cite>from_params</cite> method, you’ll have to implement
your own method that overrides this one.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.get_output_dim">
<code class="sig-name descname">get_output_dim</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/modules/text_field_embedders/basic_text_field_embedder.py#L61-L66"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.modules.text_field_embedders.basic_text_field_embedder.BasicTextFieldEmbedder.get_output_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the dimension of the vector representing each token in the output of this
<code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code>.  This is <cite>not</cite> the shape of the returned tensor, but the last element of
that shape.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.modules.time_distributed.html" class="btn btn-neutral float-right" title="allennlp.modules.time_distributed" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.modules.stacked_bidirectional_lstm.html" class="btn btn-neutral float-left" title="allennlp.modules.stacked_bidirectional_lstm" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Allen Institute for Artificial Intelligence

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>