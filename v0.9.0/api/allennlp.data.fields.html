

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.data.fields &mdash; AllenNLP 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="allennlp.data.instance" href="allennlp.data.instance.html" />
    <link rel="prev" title="allennlp.data.dataset_readers.text_classification_json" href="allennlp.data.dataset_readers.text_classification_json.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.configure.html">allennlp.commands.configure</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.make_vocab.html">allennlp.commands.make_vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.fine_tune.html">allennlp.commands.fine_tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.elmo.html">allennlp.commands.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.dry_run.html">allennlp.commands.dry_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.find_learning_rate.html">allennlp.commands.find_learning_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.test_install.html">allennlp.commands.test_install</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.print_results.html">allennlp.commands.print_results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.configuration.html">allennlp.common.configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.from_params.html">allennlp.common.from_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tqdm.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_utils.html">allennlp.data.dataset_readers.dataset_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.babi.html">allennlp.data.dataset_readers.babi</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ccgbank.html">allennlp.data.dataset_readers.ccgbank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2000.html">allennlp.data.dataset_readers.conll2000</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.event2mind.html">allennlp.data.dataset_readers.event2mind</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.interleaving_dataset_reader.html">allennlp.data.dataset_readers.interleaving_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.masked_language_modeling.html">allennlp.data.dataset_readers.masked_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.multiprocess_dataset_reader.html">allennlp.data.dataset_readers.multiprocess_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.next_token_lm.html">allennlp.data.dataset_readers.next_token_lm</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ontonotes_ner.html">allennlp.data.dataset_readers.ontonotes_ner</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.penn_tree_bank.html">allennlp.data.dataset_readers.penn_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_dependency_parsing.html">allennlp.data.dataset_readers.semantic_dependency_parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.html">allennlp.data.dataset_readers.semantic_parsing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.wikitables.html">allennlp.data.dataset_readers.semantic_parsing.wikitables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.simple_language_modeling.html">allennlp.data.dataset_readers.simple_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.stanford_sentiment_tree_bank.html">allennlp.data.dataset_readers.stanford_sentiment_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies.html">allennlp.data.dataset_readers.universal_dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies_multilang.html">allennlp.data.dataset_readers.universal_dependencies_multilang</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.copynet_seq2seq.html">allennlp.data.dataset_readers.copynet_seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.text_classification_json.html">allennlp.data.dataset_readers.text_classification_json</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.interpret.html">allennlp.interpret</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.attackers.html">allennlp.interpret.attackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.saliency_interpreters.html">allennlp.interpret.saliency_interpreters</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.basic_classifier.html">allennlp.models.basic_classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bert_for_classification.html">allennlp.models.bert_for_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser.html">allennlp.models.biaffine_dependency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser_multilang.html">allennlp.models.biaffine_dependency_parser_multilang</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biattentive_classification_network.html">allennlp.models.biattentive_classification_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bimpm.html">allennlp.models.bimpm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.constituency_parser.html">allennlp.models.constituency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.ensemble.html">allennlp.models.ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.esim.html">allennlp.models.esim</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.event2mind.html">allennlp.models.event2mind</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.graph_parser.html">allennlp.models.graph_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.language_model.html">allennlp.models.language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.masked_language_model.html">allennlp.models.masked_language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.next_token_lm.html">allennlp.models.next_token_lm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_parsing.html">allennlp.models.semantic_parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.nlvr.html">allennlp.models.semantic_parsing.nlvr</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.wikitables.html">allennlp.models.semantic_parsing.wikitables</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.atis.html">allennlp.models.semantic_parsing.atis</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.quarel.html">allennlp.models.semantic_parsing.quarel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_bert.html">allennlp.models.srl_bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_util.html">allennlp.models.srl_util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.predictors.html">allennlp.predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo.html">allennlp.modules.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.language_model_heads.html">allennlp.modules.language_model_heads</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.openai_transformer.html">allennlp.modules.openai_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_decoders.html">allennlp.modules.seq2seq_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.span_extractors.html">allennlp.modules.span_extractors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_bidirectional_lstm.html">allennlp.modules.stacked_bidirectional_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.layer_norm.html">allennlp.modules.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.pruner.html">allennlp.modules.pruner</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.maxout.html">allennlp.modules.maxout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.input_variational_dropout.html">allennlp.modules.input_variational_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.bimpm_matching.html">allennlp.modules.bimpm_matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.masked_layer_norm.html">allennlp.modules.masked_layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.sampled_softmax_loss.html">allennlp.modules.sampled_softmax_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.residual_with_layer_dropout.html">allennlp.modules.residual_with_layer_dropout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.chu_liu_edmonds.html">allennlp.nn.chu_liu_edmonds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.beam_search.html">allennlp.nn.beam_search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.semparse.html">allennlp.semparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.common.html">allennlp.semparse.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.contexts.html">allennlp.semparse.contexts</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.type_declarations.html">allennlp.semparse.type_declarations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.worlds.html">allennlp.semparse.worlds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.domain_languages.html">allennlp.semparse.domain_languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.util.html">allennlp.semparse.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_simple.html">allennlp.service.server_simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.config_explorer.html">allennlp.service.config_explorer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.state_machines.html">allennlp.state_machines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.states.html">allennlp.state_machines.states</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.trainers.html">allennlp.state_machines.trainers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.transition_functions.html">allennlp.state_machines.transition_functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.tools.html">allennlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callbacks.html">allennlp.training.callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callback_trainer.html">allennlp.training.callback_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.checkpointer.html">allennlp.training.checkpointer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.scheduler.html">allennlp.training.scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.momentum_schedulers.html">allennlp.training.momentum_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metric_tracker.html">allennlp.training.metric_tracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.moving_average.html">allennlp.training.moving_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.no_op_trainer.html">allennlp.training.no_op_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.tensorboard_writer.html">allennlp.training.tensorboard_writer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_base.html">allennlp.training.trainer_base</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_pieces.html">allennlp.training.trainer_pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.util.html">allennlp.training.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.pretrained.html">allennlp.pretrained</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.data.html">allennlp.data</a> &raquo;</li>
        
      <li>allennlp.data.fields</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.data.fields.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.data.fields">
<span id="allennlp-data-fields"></span><h1>allennlp.data.fields<a class="headerlink" href="#module-allennlp.data.fields" title="Permalink to this headline">¶</a></h1>
<p>A <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">Field</span></code></a> is some piece of data instance
that ends up as an array in a model.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#field"><span class="std std-ref">Field</span></a></p></li>
<li><p><a class="reference internal" href="#array-field"><span class="std std-ref">ArrayField</span></a></p></li>
<li><p><a class="reference internal" href="#index-field"><span class="std std-ref">IndexField</span></a></p></li>
<li><p><a class="reference internal" href="#span-field"><span class="std std-ref">SpanField</span></a></p></li>
<li><p><a class="reference internal" href="#knowledge-graph-field"><span class="std std-ref">KnowledgeGraphField</span></a></p></li>
<li><p><a class="reference internal" href="#label-field"><span class="std std-ref">LabelField</span></a></p></li>
<li><p><a class="reference internal" href="#label-field"><span class="std std-ref">MultiLabelField</span></a></p></li>
<li><p><a class="reference internal" href="#list-field"><span class="std std-ref">ListField</span></a></p></li>
<li><p><a class="reference internal" href="#metadata-field"><span class="std std-ref">MetadataField</span></a></p></li>
<li><p><a class="reference internal" href="#production-rule-field"><span class="std std-ref">ProductionRuleField</span></a></p></li>
<li><p><a class="reference internal" href="#sequence-field"><span class="std std-ref">SequenceField</span></a></p></li>
<li><p><a class="reference internal" href="#sequence-label-field"><span class="std std-ref">SequenceLabelField</span></a></p></li>
<li><p><a class="reference internal" href="#text-field"><span class="std std-ref">TextField</span></a></p></li>
<li><p><a class="reference internal" href="#adjacency-field"><span class="std std-ref">AdjacencyField</span></a></p></li>
</ul>
<span class="target" id="module-allennlp.data.fields.field"><span id="field"></span></span><dl class="class">
<dt id="allennlp.data.fields.field.Field">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.field.</code><code class="sig-name descname">Field</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L10-L116"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">typing.Generic</span></code></p>
<p>A <code class="docutils literal notranslate"><span class="pre">Field</span></code> is some piece of a data instance that ends up as an tensor in a model (either as an
input or an output).  Data instances are just collections of fields.</p>
<p>Fields go through up to two steps of processing: (1) tokenized fields are converted into token
ids, (2) fields containing token ids (or any other numeric data) are padded (if necessary) and
converted into tensors.  The <code class="docutils literal notranslate"><span class="pre">Field</span></code> API has methods around both of these steps, though they
may not be needed for some concrete <code class="docutils literal notranslate"><span class="pre">Field</span></code> classes - if your field doesn’t have any strings
that need indexing, you don’t need to implement <code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code> or <code class="docutils literal notranslate"><span class="pre">index</span></code>.  These
methods <code class="docutils literal notranslate"><span class="pre">pass</span></code> by default.</p>
<p>Once a vocabulary is computed and all fields are indexed, we will determine padding lengths,
then intelligently batch together instances and pad them into actual tensors.</p>
<dl class="method">
<dt id="allennlp.data.fields.field.Field.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; ~DataArray<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L71-L84"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.field.Field.get_padding_lengths" title="allennlp.data.fields.field.Field.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.field.Field.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[~DataArray]</em><span class="sig-paren">)</span> &#x2192; ~DataArray<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L99-L111"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.field.Field.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L25-L48"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.field.Field.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'Field'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L86-L97"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.field.Field.as_tensor" title="allennlp.data.fields.field.Field.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.field.Field.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L60-L69"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.field.Field.index" title="allennlp.data.fields.field.Field.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.field.Field.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/field.py#L50-L58"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.field.Field.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.array_field"><span id="array-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.array_field.ArrayField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.array_field.</code><code class="sig-name descname">ArrayField</code><span class="sig-paren">(</span><em class="sig-param">array: numpy.ndarray</em>, <em class="sig-param">padding_value: int = 0</em>, <em class="sig-param">dtype: numpy.dtype = &lt;class 'numpy.float32'&gt;</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/array_field.py#L10-L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.array_field.ArrayField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A class representing an array, which could have arbitrary dimensions.
A batch of these arrays are padded to the max dimension length in the batch
for each dimension.</p>
<dl class="method">
<dt id="allennlp.data.fields.array_field.ArrayField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/array_field.py#L29-L48"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.array_field.ArrayField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.array_field.ArrayField.get_padding_lengths" title="allennlp.data.fields.array_field.ArrayField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.array_field.ArrayField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/array_field.py#L50-L56"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.array_field.ArrayField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.array_field.ArrayField.as_tensor" title="allennlp.data.fields.array_field.ArrayField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.array_field.ArrayField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/array_field.py#L24-L27"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.array_field.ArrayField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.index_field"><span id="index-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.index_field.IndexField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.index_field.</code><code class="sig-name descname">IndexField</code><span class="sig-paren">(</span><em class="sig-param">index: int</em>, <em class="sig-param">sequence_field: allennlp.data.fields.sequence_field.SequenceField</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/index_field.py#L11-L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.index_field.IndexField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>An <code class="docutils literal notranslate"><span class="pre">IndexField</span></code> is an index into a
<a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code></a>, as might be used for representing
a correct answer option in a list, or a span begin and span end position in a passage, for
example.  Because it’s an index into a <code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code>, we take one of those as input
and use it to compute padding lengths.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>index</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd><p>The index of the answer in the <code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code>.  This is typically the “correct
answer” in some classification decision over the sequence, like where an answer span starts
in SQuAD, or which answer option is correct in a multiple choice question.  A value of
<code class="docutils literal notranslate"><span class="pre">-1</span></code> means there is no label, which can be used for padding or other purposes.</p>
</dd>
<dt><strong>sequence_field</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">SequenceField</span></code></span></dt><dd><p>A field containing the sequence that this <code class="docutils literal notranslate"><span class="pre">IndexField</span></code> is a pointer into.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.index_field.IndexField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/index_field.py#L42-L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.index_field.IndexField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.index_field.IndexField.get_padding_lengths" title="allennlp.data.fields.index_field.IndexField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.index_field.IndexField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/index_field.py#L48-L50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.index_field.IndexField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.index_field.IndexField.as_tensor" title="allennlp.data.fields.index_field.IndexField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.index_field.IndexField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/index_field.py#L37-L40"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.index_field.IndexField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.span_field"><span id="span-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.span_field.SpanField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.span_field.</code><code class="sig-name descname">SpanField</code><span class="sig-paren">(</span><em class="sig-param">span_start: int</em>, <em class="sig-param">span_end: int</em>, <em class="sig-param">sequence_field: allennlp.data.fields.sequence_field.SequenceField</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/span_field.py#L11-L65"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.span_field.SpanField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">SpanField</span></code> is a pair of inclusive, zero-indexed (start, end) indices into a
<a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code></a>, used to represent a span of text.
Because it’s a pair of indices into a <code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code>, we take one of those as input
to make the span’s dependence explicit and to validate that the span is well defined.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>span_start</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required.</span></dt><dd><p>The index of the start of the span in the <code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code>.</p>
</dd>
<dt><strong>span_end</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required.</span></dt><dd><p>The inclusive index of the end of the span in the <code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code>.</p>
</dd>
<dt><strong>sequence_field</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">SequenceField</span></code>, required.</span></dt><dd><p>A field containing the sequence that this <code class="docutils literal notranslate"><span class="pre">SpanField</span></code> is a span inside.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.span_field.SpanField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/span_field.py#L49-L53"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.span_field.SpanField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.span_field.SpanField.get_padding_lengths" title="allennlp.data.fields.span_field.SpanField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.span_field.SpanField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/span_field.py#L55-L57"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.span_field.SpanField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.span_field.SpanField.as_tensor" title="allennlp.data.fields.span_field.SpanField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.span_field.SpanField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/span_field.py#L44-L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.span_field.SpanField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.knowledge_graph_field"><span id="knowledge-graph-field"></span></span><p><code class="docutils literal notranslate"><span class="pre">KnowledgeGraphField</span></code> is a <code class="docutils literal notranslate"><span class="pre">Field</span></code> which stores a knowledge graph representation.</p>
<dl class="class">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.knowledge_graph_field.</code><code class="sig-name descname">KnowledgeGraphField</code><span class="sig-paren">(</span><em class="sig-param">knowledge_graph: allennlp.semparse.contexts.knowledge_graph.KnowledgeGraph, utterance_tokens: List[allennlp.data.tokenizers.token.Token], token_indexers: Dict[str, allennlp.data.token_indexers.token_indexer.TokenIndexer], tokenizer: allennlp.data.tokenizers.tokenizer.Tokenizer = None, feature_extractors: List[str] = None, entity_tokens: List[List[allennlp.data.tokenizers.token.Token]] = None, linking_features: List[List[List[float]]] = None, include_in_vocab: bool = True, max_table_tokens: int = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L25-L436"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">KnowledgeGraphField</span></code> represents a <code class="docutils literal notranslate"><span class="pre">KnowledgeGraph</span></code> as a <code class="docutils literal notranslate"><span class="pre">Field</span></code> that can be used in a
<code class="docutils literal notranslate"><span class="pre">Model</span></code>.  For each entity in the graph, we output two things: a text representation of the
entity, handled identically to a <code class="docutils literal notranslate"><span class="pre">TextField</span></code>, and a list of linking features for each token
in some input utterance.</p>
<p>The output of this field is a dictionary:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>  <span class="c1"># each tensor has shape (batch_size, num_entities, num_entity_tokens)</span>
  <span class="s2">&quot;linking&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>  <span class="c1"># shape (batch_size, num_entities, num_utterance_tokens, num_features)</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">text</span></code> component of this dictionary is suitable to be passed into a
<code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code> (which handles the additional <code class="docutils literal notranslate"><span class="pre">num_entities</span></code> dimension without any
issues).  The <code class="docutils literal notranslate"><span class="pre">linking</span></code> component of the dictionary can be used however you want to decide
which tokens in the utterance correspond to which entities in the knowledge graph.</p>
<p>In order to create the <code class="docutils literal notranslate"><span class="pre">text</span></code> component, we use the same dictionary of <code class="docutils literal notranslate"><span class="pre">TokenIndexers</span></code>
that’s used in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> (as we’re just representing the text corresponding to each
entity).  For the <code class="docutils literal notranslate"><span class="pre">linking</span></code> component, we use a set of hard-coded feature extractors that
operate between the text corresponding to each entity and each token in the utterance.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>knowledge_graph</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">KnowledgeGraph</span></code></span></dt><dd><p>The knowledge graph that this field stores.</p>
</dd>
<dt><strong>utterance_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Token]</span></code></span></dt><dd><p>The tokens in some utterance that is paired with the <code class="docutils literal notranslate"><span class="pre">KnowledgeGraph</span></code>.  We compute a set
of features for linking tokens in the utterance to entities in the graph.</p>
</dd>
<dt><strong>tokenizer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code>, optional (default=``WordTokenizer()``)</span></dt><dd><p>We’ll use this <code class="docutils literal notranslate"><span class="pre">Tokenizer</span></code> to tokenize the text representation of each entity.</p>
</dd>
<dt><strong>token_indexers</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">TokenIndexer]</span></code></span></dt><dd><p>Token indexers that convert entities into arrays, similar to how text tokens are treated in
a <code class="docutils literal notranslate"><span class="pre">TextField</span></code>.  These might operate on the name of the entity itself, its type, its
neighbors in the graph, etc.</p>
</dd>
<dt><strong>feature_extractors</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[str]</span></code>, optional</span></dt><dd><p>Names of feature extractors to use for computing linking features.  These must be
attributes of this object, without the first underscore.  The feature extraction functions
are listed as the last methods in this class.  For example, to use
<code class="xref py py-func docutils literal notranslate"><span class="pre">_exact_token_match()</span></code>, you would pass the string <code class="docutils literal notranslate"><span class="pre">exact_token_match</span></code>.  We will add
an underscore and look for a function matching that name.  If this list is omitted, we will
use all available feature functions.</p>
</dd>
<dt><strong>entity_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[List[Token]]</span></code>, optional</span></dt><dd><p>If you have pre-computed the tokenization of the table text, you can pass it in here.  The
must be a list of the tokens in the entity text, for each entity in the knowledge graph, in
the same order in which the knowledge graph returns entities.</p>
</dd>
<dt><strong>linking_features</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[List[List[float]]]</span></code>, optional</span></dt><dd><p>If you have pre-computed the linking features between the utterance and the table text, you
can pass it in here.</p>
</dd>
<dt><strong>include_in_vocab</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=True)</span></dt><dd><p>If this is <code class="docutils literal notranslate"><span class="pre">False</span></code>, we will skip the <code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code> logic, leaving out all table
entity text from the vocabulary computation.  You might want to do this if you have a lot
of rare entities in your tables, and you see the same table in multiple training instances,
so your vocabulary counts get skewed and include too many rare entities.</p>
</dd>
<dt><strong>max_table_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional</span></dt><dd><p>If given, we will only keep this number of total table tokens.  This bounds the memory
usage of the table representations, truncating cells with really long text.  We specify a
total number of tokens, not a max cell text length, because the number of table entities
varies.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L213-L242"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths" title="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L264-L269"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L155-L161"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'KnowledgeGraphField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L260-L262"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor" title="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L175-L211"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.index" title="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/knowledge_graph_field.py#L163-L173"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.knowledge_graph_field.KnowledgeGraphField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.label_field"><span id="label-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.label_field.LabelField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.label_field.</code><code class="sig-name descname">LabelField</code><span class="sig-paren">(</span><em class="sig-param">label: Union[str, int], label_namespace: str = 'labels', skip_indexing: bool = False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L14-L99"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> is a categorical label of some kind, where the labels are either strings of
text or 0-indexed integers (if you wish to skip indexing by passing skip_indexing=True).
If the labels need indexing, we will use a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code> to convert the string labels
into integers.</p>
<p>This field will get converted into an integer index representing the class label.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>label</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Union[str,</span> <span class="pre">int]</span></code></span></dt><dd></dd>
<dt><strong>label_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=”labels”)</span></dt><dd><p>The namespace to use for converting label strings into integers.  We map label strings to
integers for you (e.g., “entailment” and “contradiction” get converted to 0, 1, …),
and this namespace tells the <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> object which mapping from strings to integers
to use (so “entailment” as a label doesn’t get the same integer id as “entailment” as a
word).  If you have multiple different label fields in your data, you should make sure you
use different namespaces for each one, always using the suffix “labels” (e.g.,
“passage_labels” and “question_labels”).</p>
</dd>
<dt><strong>skip_indexing</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=False)</span></dt><dd><p>If your labels are 0-indexed integers, you can pass in this flag, and we’ll skip the indexing
step.  If this is <code class="docutils literal notranslate"><span class="pre">False</span></code> and your labels are not strings, this throws a <code class="docutils literal notranslate"><span class="pre">ConfigurationError</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.label_field.LabelField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L88-L92"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.label_field.LabelField.get_padding_lengths" title="allennlp.data.fields.label_field.LabelField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.label_field.LabelField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L74-L77"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.label_field.LabelField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L94-L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.label_field.LabelField.as_tensor" title="allennlp.data.fields.label_field.LabelField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.label_field.LabelField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L84-L86"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.label_field.LabelField.index" title="allennlp.data.fields.label_field.LabelField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.label_field.LabelField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/label_field.py#L79-L82"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.label_field.LabelField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.multilabel_field"><span id="multilabel-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.multilabel_field.</code><code class="sig-name descname">MultiLabelField</code><span class="sig-paren">(</span><em class="sig-param">labels: Sequence[Union[str, int]], label_namespace: str = 'labels', skip_indexing: bool = False, num_labels: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L14-L123"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">MultiLabelField</span></code> is an extension of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LabelField</span></code> that allows for multiple labels.
It is particularly useful in multi-label classification where more than one label can be correct.
As with the <code class="xref py py-class docutils literal notranslate"><span class="pre">LabelField</span></code>, labels are either strings of text or 0-indexed integers (if you wish
to skip indexing by passing skip_indexing=True).
If the labels need indexing, we will use a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code> to convert the string labels
into integers.</p>
<p>This field will get converted into a vector of length equal to the vocabulary size with
one hot encoding for the labels (all zeros, and ones for the labels).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>labels</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Sequence[Union[str,</span> <span class="pre">int]]</span></code></span></dt><dd></dd>
<dt><strong>label_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=”labels”)</span></dt><dd><p>The namespace to use for converting label strings into integers.  We map label strings to
integers for you (e.g., “entailment” and “contradiction” get converted to 0, 1, …),
and this namespace tells the <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> object which mapping from strings to integers
to use (so “entailment” as a label doesn’t get the same integer id as “entailment” as a
word).  If you have multiple different label fields in your data, you should make sure you
use different namespaces for each one, always using the suffix “labels” (e.g.,
“passage_labels” and “question_labels”).</p>
</dd>
<dt><strong>skip_indexing</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default=False)</span></dt><dd><p>If your labels are 0-indexed integers, you can pass in this flag, and we’ll skip the indexing
step.  If this is <code class="docutils literal notranslate"><span class="pre">False</span></code> and your labels are not strings, this throws a <code class="docutils literal notranslate"><span class="pre">ConfigurationError</span></code>.</p>
</dd>
<dt><strong>num_labels</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default=None)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">skip_indexing=True</span></code>, the total number of possible labels should be provided, which is required
to decide the size of the output tensor. <cite>num_labels</cite> should equal largest label id + 1.
If <code class="docutils literal notranslate"><span class="pre">skip_indexing=False</span></code>, <cite>num_labels</cite> is not required.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L108-L116"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.multilabel_field.MultiLabelField.get_padding_lengths" title="allennlp.data.fields.multilabel_field.MultiLabelField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L90-L94"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L118-L120"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.multilabel_field.MultiLabelField.as_tensor" title="allennlp.data.fields.multilabel_field.MultiLabelField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L104-L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.multilabel_field.MultiLabelField.index" title="allennlp.data.fields.multilabel_field.MultiLabelField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.multilabel_field.MultiLabelField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/multilabel_field.py#L96-L102"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.multilabel_field.MultiLabelField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.list_field"><span id="list-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.list_field.ListField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.list_field.</code><code class="sig-name descname">ListField</code><span class="sig-paren">(</span><em class="sig-param">field_list: List[allennlp.data.fields.field.Field]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L12-L115"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.sequence_field.SequenceField</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">ListField</span></code> is a list of other fields.  You would use this to represent, e.g., a list of
answer options that are themselves <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>.</p>
<p>This field will get converted into a tensor that has one more mode than the items in the list.
If this is a list of <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> that have shape (num_words, num_characters), this
<code class="docutils literal notranslate"><span class="pre">ListField</span></code> will output a tensor of shape (num_sentences, num_words, num_characters).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>field_list</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Field]</span></code></span></dt><dd><p>A list of <code class="docutils literal notranslate"><span class="pre">Field</span></code> objects to be concatenated into a single input tensor.  All of the
contained <code class="docutils literal notranslate"><span class="pre">Field</span></code> objects must be of the same type.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; ~DataArray<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L82-L94"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.list_field.ListField.get_padding_lengths" title="allennlp.data.fields.list_field.ListField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[~DataArray]</em><span class="sig-paren">)</span> &#x2192; ~DataArray<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L107-L110"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L44-L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L96-L105"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.list_field.ListField.as_tensor" title="allennlp.data.fields.list_field.ListField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L54-L76"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.list_field.ListField.index" title="allennlp.data.fields.list_field.ListField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L49-L52"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.list_field.ListField.sequence_length">
<code class="sig-name descname">sequence_length</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/list_field.py#L78-L80"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.list_field.ListField.sequence_length" title="Permalink to this definition">¶</a></dt>
<dd><p>How many elements are there in this sequence?</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.metadata_field"><span id="metadata-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.metadata_field.MetadataField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.metadata_field.</code><code class="sig-name descname">MetadataField</code><span class="sig-paren">(</span><em class="sig-param">metadata: Any</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/metadata_field.py#L9-L66"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.metadata_field.MetadataField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">collections.abc.Mapping</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">typing.Generic</span></code></p>
<p>A <code class="docutils literal notranslate"><span class="pre">MetadataField</span></code> is a <code class="docutils literal notranslate"><span class="pre">Field</span></code> that does not get converted into tensors.  It just carries
side information that might be needed later on, for computing some third-party metric, or
outputting debugging information, or whatever else you need.  We use this in the BiDAF model,
for instance, to keep track of question IDs and passage token offsets, so we can more easily
use the official evaluation script to compute metrics.</p>
<p>We don’t try to do any kind of smart combination of this field for batched input - when you use
this <code class="docutils literal notranslate"><span class="pre">Field</span></code> in a model, you’ll get a list of metadata objects, one for each instance in the
batch.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>metadata</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Any</span></code></span></dt><dd><p>Some object containing the metadata that you want to store.  It’s likely that you’ll want
this to be a dictionary, but it could be anything you want.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.metadata_field.MetadataField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; ~DataArray<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/metadata_field.py#L52-L55"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.metadata_field.MetadataField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.metadata_field.MetadataField.get_padding_lengths" title="allennlp.data.fields.metadata_field.MetadataField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.metadata_field.MetadataField.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[~DataArray]</em><span class="sig-paren">)</span> &#x2192; List[~DataArray]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/metadata_field.py#L61-L63"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.metadata_field.MetadataField.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.metadata_field.MetadataField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'MetadataField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/metadata_field.py#L57-L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.metadata_field.MetadataField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.metadata_field.MetadataField.as_tensor" title="allennlp.data.fields.metadata_field.MetadataField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.metadata_field.MetadataField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/metadata_field.py#L48-L50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.metadata_field.MetadataField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.production_rule_field"><span id="production-rule-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.production_rule_field.ProductionRule">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.production_rule_field.</code><code class="sig-name descname">ProductionRule</code><span class="sig-paren">(</span><em class="sig-param">rule</em>, <em class="sig-param">is_global_rule</em>, <em class="sig-param">rule_id</em>, <em class="sig-param">nonterminal</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L9-L13"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRule.is_global_rule">
<em class="property">property </em><code class="sig-name descname">is_global_rule</code><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRule.is_global_rule" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRule.nonterminal">
<em class="property">property </em><code class="sig-name descname">nonterminal</code><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRule.nonterminal" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRule.rule">
<em class="property">property </em><code class="sig-name descname">rule</code><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRule.rule" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRule.rule_id">
<em class="property">property </em><code class="sig-name descname">rule_id</code><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRule.rule_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleArray">
<code class="sig-prename descclassname">allennlp.data.fields.production_rule_field.</code><code class="sig-name descname">ProductionRuleArray</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L9-L13"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleArray" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#allennlp.data.fields.production_rule_field.ProductionRule" title="allennlp.data.fields.production_rule_field.ProductionRule"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.production_rule_field.ProductionRule</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.production_rule_field.</code><code class="sig-name descname">ProductionRuleField</code><span class="sig-paren">(</span><em class="sig-param">rule: str</em>, <em class="sig-param">is_global_rule: bool</em>, <em class="sig-param">vocab_namespace: str = 'rule_labels'</em>, <em class="sig-param">nonterminal: str = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L22-L122"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>This <code class="docutils literal notranslate"><span class="pre">Field</span></code> represents a production rule from a grammar, like “S -&gt; [NP, VP]”, “N -&gt; John”,
or “&lt;b,c&gt; -&gt; [&lt;a,&lt;b,c&gt;&gt;, a]”.</p>
<p>We assume a few things about how these rules are formatted:</p>
<blockquote>
<div><ul class="simple">
<li><p>There is a left-hand side (LHS) and a right-hand side (RHS), where the LHS is always a
non-terminal, and the RHS is either a terminal, a non-terminal, or a sequence of
terminals and/or non-terminals.</p></li>
<li><p>The LHS and the RHS are joined by ” -&gt; “, and this sequence of characters appears nowhere
else in the rule.</p></li>
<li><p>Non-terminal sequences in the RHS are formatted as “[NT1, NT2, …]”.</p></li>
<li><p>Some rules come from a global grammar used for a whole dataset, while other rules are
specific to a particular <code class="docutils literal notranslate"><span class="pre">Instance</span></code>.</p></li>
</ul>
</div></blockquote>
<p>We don’t make use of most of these assumptions in this class, but the code that consumes this
<code class="docutils literal notranslate"><span class="pre">Field</span></code> relies heavily on them in some places.</p>
<p>If the given rule is in the global grammar, we treat the rule as a vocabulary item that will
get an index and (in the model) an embedding.  If the rule is not in the global grammar, we do
not create a vocabulary item from the rule, and don’t produce a tensor for the rule - we assume
the model will handle representing this rule in some other way.</p>
<p>Because we represent global grammar rules and instance-specific rules differently, this
<code class="docutils literal notranslate"><span class="pre">Field</span></code> does not lend itself well to batching its arrays, even in a sequence for a single
training instance.  A model using this field will have to manually batch together rule
representations after splitting apart the global rules from the <code class="docutils literal notranslate"><span class="pre">Instance</span></code> rules.</p>
<p>In a model, this will get represented as a <code class="docutils literal notranslate"><span class="pre">ProductionRule</span></code>, which is defined above.
This is a namedtuple of <code class="docutils literal notranslate"><span class="pre">(rule_string,</span> <span class="pre">is_global_rule,</span> <span class="pre">[rule_id],</span> <span class="pre">nonterminal)</span></code>, where the
<code class="docutils literal notranslate"><span class="pre">rule_id</span></code> <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, if present, will have shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code>.  We don’t do any batching of the
<code class="docutils literal notranslate"><span class="pre">Tensors</span></code>, so this gets passed to <code class="docutils literal notranslate"><span class="pre">Model.forward()</span></code> as a <code class="docutils literal notranslate"><span class="pre">List[ProductionRule]</span></code>.  We
pass along the rule string because there isn’t another way to recover it for instance-specific
rules that do not make it into the vocabulary.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>rule</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code></span></dt><dd><p>The production rule, formatted as described above.  If this field is just padding, <code class="docutils literal notranslate"><span class="pre">rule</span></code>
will be the empty string.</p>
</dd>
<dt><strong>is_global_rule</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code></span></dt><dd><p>Whether this rule comes from the global grammar or is an instance-specific production rule.</p>
</dd>
<dt><strong>vocab_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=”rule_labels”)</span></dt><dd><p>The vocabulary namespace to use for the global production rules.  We use “rule_labels” by
default, because we typically do not want padding and OOV tokens for these, and ending the
namespace with “labels” means we don’t get padding and OOV tokens.</p>
</dd>
<dt><strong>nonterminal</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional, default = None</span></dt><dd><p>The left hand side of the rule. Sometimes having this as separate part of the <code class="docutils literal notranslate"><span class="pre">ProductionRule</span></code>
can deduplicate work.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; allennlp.data.fields.production_rule_field.ProductionRule<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L99-L106"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.get_padding_lengths" title="allennlp.data.fields.production_rule_field.ProductionRuleField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[allennlp.data.fields.production_rule_field.ProductionRule]</em><span class="sig-paren">)</span> &#x2192; List[allennlp.data.fields.production_rule_field.ProductionRule]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L115-L118"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L84-L87"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L108-L113"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.as_tensor" title="allennlp.data.fields.production_rule_field.ProductionRuleField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L94-L97"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.index" title="allennlp.data.fields.production_rule_field.ProductionRuleField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.production_rule_field.ProductionRuleField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/production_rule_field.py#L89-L92"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.production_rule_field.ProductionRuleField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.sequence_field"><span id="sequence-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.sequence_field.SequenceField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.sequence_field.</code><code class="sig-name descname">SequenceField</code><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_field.py#L4-L18"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_field.SequenceField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">SequenceField</span></code> represents a sequence of things.  This class just adds a method onto
<code class="docutils literal notranslate"><span class="pre">Field</span></code>: <a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField.sequence_length" title="allennlp.data.fields.sequence_field.SequenceField.sequence_length"><code class="xref py py-func docutils literal notranslate"><span class="pre">sequence_length()</span></code></a>.  It exists so that <code class="docutils literal notranslate"><span class="pre">SequenceLabelField</span></code>, <code class="docutils literal notranslate"><span class="pre">IndexField</span></code> and other
similar <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can have a single type to require, with a consistent API, whether they are
pointing to words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code>, items in a <code class="docutils literal notranslate"><span class="pre">ListField</span></code>, or something else.</p>
<dl class="method">
<dt id="allennlp.data.fields.sequence_field.SequenceField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'SequenceField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_field.py#L17-L18"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_field.SequenceField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.sequence_field.SequenceField.sequence_length">
<code class="sig-name descname">sequence_length</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_field.py#L11-L15"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_field.SequenceField.sequence_length" title="Permalink to this definition">¶</a></dt>
<dd><p>How many elements are there in this sequence?</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.sequence_label_field"><span id="sequence-label-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.sequence_label_field.</code><code class="sig-name descname">SequenceLabelField</code><span class="sig-paren">(</span><em class="sig-param">labels: Union[List[str], List[int]], sequence_field: allennlp.data.fields.sequence_field.SequenceField, label_namespace: str = 'labels'</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L17-L127"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">SequenceLabelField</span></code> assigns a categorical label to each element in a
<a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code></a>.
Because it’s a labeling of some other field, we take that field as input here, and we use it to
determine our padding and other things.</p>
<p>This field will get converted into a list of integer class ids, representing the correct class
for each element in the sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>labels</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Union[List[str],</span> <span class="pre">List[int]]</span></code></span></dt><dd><p>A sequence of categorical labels, encoded as strings or integers.  These could be POS tags like [NN,
JJ, …], BIO tags like [B-PERS, I-PERS, O, O, …], or any other categorical tag sequence. If the
labels are encoded as integers, they will not be indexed using a vocab.</p>
</dd>
<dt><strong>sequence_field</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">SequenceField</span></code></span></dt><dd><p>A field containing the sequence that this <code class="docutils literal notranslate"><span class="pre">SequenceLabelField</span></code> is labeling.  Most often, this is a
<code class="docutils literal notranslate"><span class="pre">TextField</span></code>, for tagging individual tokens in a sentence.</p>
</dd>
<dt><strong>label_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=’labels’)</span></dt><dd><p>The namespace to use for converting tag strings into integers.  We convert tag strings to
integers for you, and this parameter tells the <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> object which mapping from
strings to integers to use (so that “O” as a tag doesn’t get the same id as “O” as a word).</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L106-L111"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.get_padding_lengths" title="allennlp.data.fields.sequence_label_field.SequenceLabelField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L90-L94"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'SequenceLabelField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L113-L120"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.as_tensor" title="allennlp.data.fields.sequence_label_field.SequenceLabelField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L102-L104"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.index" title="allennlp.data.fields.sequence_label_field.SequenceLabelField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.sequence_label_field.SequenceLabelField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/sequence_label_field.py#L96-L100"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.sequence_label_field.SequenceLabelField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.text_field"><span id="text-field"></span></span><p>A <code class="docutils literal notranslate"><span class="pre">TextField</span></code> represents a string of text, the kind that you might want to represent with
standard word vectors, or pass through an LSTM.</p>
<dl class="class">
<dt id="allennlp.data.fields.text_field.TextField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.text_field.</code><code class="sig-name descname">TextField</code><span class="sig-paren">(</span><em class="sig-param">tokens: List[allennlp.data.tokenizers.token.Token], token_indexers: Dict[str, allennlp.data.token_indexers.token_indexer.TokenIndexer]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L22-L184"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.sequence_field.SequenceField</span></code></a></p>
<p>This <code class="docutils literal notranslate"><span class="pre">Field</span></code> represents a list of string tokens.  Before constructing this object, you need
to tokenize raw strings using a <a class="reference internal" href="allennlp.data.tokenizers.html#allennlp.data.tokenizers.tokenizer.Tokenizer" title="allennlp.data.tokenizers.tokenizer.Tokenizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tokenizer</span></code></a>.</p>
<p>Because string tokens can be represented as indexed arrays in a number of ways, we also take a
dictionary of <a class="reference internal" href="allennlp.data.token_indexers.html#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal notranslate"><span class="pre">TokenIndexer</span></code></a>
objects that will be used to convert the tokens into indices.
Each <code class="docutils literal notranslate"><span class="pre">TokenIndexer</span></code> could represent each token as a single ID, or a list of character IDs, or
something else.</p>
<p>This field will get converted into a dictionary of arrays, one for each <code class="docutils literal notranslate"><span class="pre">TokenIndexer</span></code>.  A
<code class="docutils literal notranslate"><span class="pre">SingleIdTokenIndexer</span></code> produces an array of shape (num_tokens,), while a
<code class="docutils literal notranslate"><span class="pre">TokenCharactersIndexer</span></code> produces an array of shape (num_tokens, num_characters).</p>
<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L139-L155"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.text_field.TextField.get_padding_lengths" title="allennlp.data.fields.text_field.TextField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.batch_tensors">
<code class="sig-name descname">batch_tensors</code><span class="sig-paren">(</span><em class="sig-param">self, tensor_list: List[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L170-L175"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.batch_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the output of <code class="docutils literal notranslate"><span class="pre">Field.as_tensor()</span></code> from a list of <code class="docutils literal notranslate"><span class="pre">Instances</span></code> and merges it into
one batched tensor for this <code class="docutils literal notranslate"><span class="pre">Field</span></code>.  The default implementation here in the base class
handles cases where <code class="docutils literal notranslate"><span class="pre">as_tensor</span></code> returns a single torch tensor per instance.  If your
subclass returns something other than this, you need to override this method.</p>
<p>This operation does not modify <code class="docutils literal notranslate"><span class="pre">self</span></code>, but in some cases we need the information
contained in <code class="docutils literal notranslate"><span class="pre">self</span></code> in order to perform the batching, so this is an instance method, not
a class method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L58-L62"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L157-L168"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.text_field.TextField.as_tensor" title="allennlp.data.fields.text_field.TextField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L79-L133"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="docutils literal notranslate"><span class="pre">TextField</span></code> has a list of <code class="docutils literal notranslate"><span class="pre">Tokens</span></code>, and each <code class="docutils literal notranslate"><span class="pre">Token</span></code> gets converted into arrays by
(potentially) several <code class="docutils literal notranslate"><span class="pre">TokenIndexers</span></code>.  This method gets the max length (over tokens)
associated with each of these arrays.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L64-L77"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.text_field.TextField.sequence_length">
<code class="sig-name descname">sequence_length</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/text_field.py#L135-L137"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.text_field.TextField.sequence_length" title="Permalink to this definition">¶</a></dt>
<dd><p>How many elements are there in this sequence?</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.adjacency_field"><span id="adjacency-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.adjacency_field.</code><code class="sig-name descname">AdjacencyField</code><span class="sig-paren">(</span><em class="sig-param">indices: List[Tuple[int, int]], sequence_field: allennlp.data.fields.sequence_field.SequenceField, labels: List[str] = None, label_namespace: str = 'labels', padding_value: int = -1</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L16-L129"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">AdjacencyField</span></code> defines directed adjacency relations between elements
in a <a class="reference internal" href="#allennlp.data.fields.sequence_field.SequenceField" title="allennlp.data.fields.sequence_field.SequenceField"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequenceField</span></code></a>.
Because it’s a labeling of some other field, we take that field as input here
and use it to determine our padding and other things.</p>
<p>This field will get converted into an array of shape (sequence_field_length, sequence_field_length),
where the (i, j)th array element is either a binary flag indicating there is an edge from i to j,
or an integer label k, indicating there is a label from i to j of type k.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>indices</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Tuple[int,</span> <span class="pre">int]]</span></code></span></dt><dd></dd>
<dt><strong>sequence_field</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">SequenceField</span></code></span></dt><dd><p>A field containing the sequence that this <code class="docutils literal notranslate"><span class="pre">AdjacencyField</span></code> is labeling.  Most often,
this is a <code class="docutils literal notranslate"><span class="pre">TextField</span></code>, for tagging edge relations between tokens in a sentence.</p>
</dd>
<dt><strong>labels</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[str]</span></code>, optional, default = None</span></dt><dd><p>Optional labels for the edges of the adjacency matrix.</p>
</dd>
<dt><strong>label_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=’labels’)</span></dt><dd><p>The namespace to use for converting tag strings into integers.  We convert tag strings to
integers for you, and this parameter tells the <code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code> object which mapping from
strings to integers to use (so that “O” as a tag doesn’t get the same id as “O” as a word).</p>
</dd>
<dt><strong>padding_value</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, (optional, default = -1)</span></dt><dd><p>The value to use as padding.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L101-L109"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.adjacency_field.AdjacencyField.get_padding_lengths" title="allennlp.data.fields.adjacency_field.AdjacencyField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField.count_vocab_items">
<code class="sig-name descname">count_vocab_items</code><span class="sig-paren">(</span><em class="sig-param">self, counter: Dict[str, Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L85-L89"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are strings in this field that need to be converted into integers through a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, here is where we count them, to determine which tokens are in or out
of the vocabulary.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
<p>A note on this <code class="docutils literal notranslate"><span class="pre">counter</span></code>: because <code class="docutils literal notranslate"><span class="pre">Fields</span></code> can represent conceptually different things,
we separate the vocabulary items by <cite>namespaces</cite>.  This way, we can use a single shared
mechanism to handle all mappings from strings to integers in all fields, while keeping
words in a <code class="docutils literal notranslate"><span class="pre">TextField</span></code> from sharing the same ids with labels in a <code class="docutils literal notranslate"><span class="pre">LabelField</span></code> (e.g.,
“entailment” or “contradiction” are labels in an entailment task)</p>
<p>Additionally, a single <code class="docutils literal notranslate"><span class="pre">Field</span></code> might want to use multiple namespaces - <code class="docutils literal notranslate"><span class="pre">TextFields</span></code> can
be represented as a combination of word ids and character ids, and you don’t want words and
characters to share the same vocabulary - “a” as a word should get a different id from “a”
as a character, and the vocabulary sizes of words and characters are very different.</p>
<p>Because of this, the first key in the <code class="docutils literal notranslate"><span class="pre">counter</span></code> object is a <cite>namespace</cite>, like “tokens”,
“token_characters”, “tags”, or “labels”, and the second key is the actual vocabulary item.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'AdjacencyField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L111-L119"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.adjacency_field.AdjacencyField.as_tensor" title="allennlp.data.fields.adjacency_field.AdjacencyField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L97-L99"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.adjacency_field.AdjacencyField.index" title="allennlp.data.fields.adjacency_field.AdjacencyField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.adjacency_field.AdjacencyField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/adjacency_field.py#L91-L95"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.adjacency_field.AdjacencyField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.fields.namespace_swapping_field"><span id="namespace-swapping-field"></span></span><dl class="class">
<dt id="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.data.fields.namespace_swapping_field.</code><code class="sig-name descname">NamespaceSwappingField</code><span class="sig-paren">(</span><em class="sig-param">source_tokens: List[allennlp.data.tokenizers.token.Token], target_namespace: str</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/namespace_swapping_field.py#L12-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.fields.field.Field" title="allennlp.data.fields.field.Field"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.data.fields.field.Field</span></code></a></p>
<p>A <code class="docutils literal notranslate"><span class="pre">NamespaceSwappingField</span></code> is used to map tokens in one namespace to tokens in another namespace.
It is used by seq2seq models with a copy mechanism that copies tokens from the source
sentence into the target sentence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>source_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Token]</span></code></span></dt><dd><p>The tokens from the source sentence.</p>
</dd>
<dt><strong>target_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code></span></dt><dd><p>The namespace that the tokens from the source sentence will be mapped to.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.as_tensor">
<code class="sig-name descname">as_tensor</code><span class="sig-paren">(</span><em class="sig-param">self, padding_lengths: Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/namespace_swapping_field.py#L42-L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.as_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of specified padding lengths, actually pad the data in this field and return a
torch Tensor (or a more complex data structure) of the correct shape.  We also take a
couple of parameters that are important when constructing torch Tensors.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>padding_lengths</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">int]</span></code></span></dt><dd><p>This dictionary will have the same keys that were produced in
<a class="reference internal" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.get_padding_lengths" title="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.get_padding_lengths"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_padding_lengths()</span></code></a>.  The values specify the lengths to use when padding each
relevant dimension, aggregated across all instances in a batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.empty_field">
<code class="sig-name descname">empty_field</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; 'NamespaceSwappingField'<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/namespace_swapping_field.py#L49-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.empty_field" title="Permalink to this definition">¶</a></dt>
<dd><p>So that <code class="docutils literal notranslate"><span class="pre">ListField</span></code> can pad the number of fields in a list (e.g., the number of answer
option <code class="docutils literal notranslate"><span class="pre">TextFields</span></code>), we need a representation of an empty field of each type.  This
returns that.  This will only ever be called when we’re to the point of calling
<a class="reference internal" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.as_tensor" title="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">as_tensor()</span></code></a>, so you don’t need to worry about <code class="docutils literal notranslate"><span class="pre">get_padding_lengths</span></code>,
<code class="docutils literal notranslate"><span class="pre">count_vocab_items</span></code>, etc., being called on this empty field.</p>
<p>We make this an instance method instead of a static method so that if there is any state
in the Field, we can copy it over (e.g., the token indexers in <code class="docutils literal notranslate"><span class="pre">TextField</span></code>).</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.get_padding_lengths">
<code class="sig-name descname">get_padding_lengths</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span> &#x2192; Dict[str, int]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/namespace_swapping_field.py#L38-L40"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>If there are things in this field that need padding, note them here.  In order to pad a
batch of instance, we get all of the lengths from the batch, take the max, and pad
everything to that length (or use a pre-specified maximum length).  The return value is a
dictionary mapping keys to lengths, like {‘num_tokens’: 13}.</p>
<p>This is always called after <a class="reference internal" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.index" title="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.index"><code class="xref py py-func docutils literal notranslate"><span class="pre">index()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.index">
<code class="sig-name descname">index</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/data/fields/namespace_swapping_field.py#L33-L36"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.fields.namespace_swapping_field.NamespaceSwappingField.index" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-class docutils literal notranslate"><span class="pre">Vocabulary</span></code>, converts all strings in this field into (typically) integers.
This <cite>modifies</cite> the <code class="docutils literal notranslate"><span class="pre">Field</span></code> object, it does not return anything.</p>
<p>If your <code class="docutils literal notranslate"><span class="pre">Field</span></code> does not have any strings that need to be converted into indices, you do
not need to implement this method.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.data.instance.html" class="btn btn-neutral float-right" title="allennlp.data.instance" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.data.dataset_readers.text_classification_json.html" class="btn btn-neutral float-left" title="allennlp.data.dataset_readers.text_classification_json" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Allen Institute for Artificial Intelligence

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>