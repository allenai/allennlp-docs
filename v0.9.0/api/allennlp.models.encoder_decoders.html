

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.models.encoder_decoders &mdash; AllenNLP 0.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="allennlp.models.ensemble" href="allennlp.models.ensemble.html" />
    <link rel="prev" title="allennlp.models.decomposable_attention" href="allennlp.models.decomposable_attention.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.configure.html">allennlp.commands.configure</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.make_vocab.html">allennlp.commands.make_vocab</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.fine_tune.html">allennlp.commands.fine_tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.elmo.html">allennlp.commands.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.dry_run.html">allennlp.commands.dry_run</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.find_learning_rate.html">allennlp.commands.find_learning_rate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.test_install.html">allennlp.commands.test_install</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.print_results.html">allennlp.commands.print_results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.configuration.html">allennlp.common.configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.from_params.html">allennlp.common.from_params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tqdm.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_utils.html">allennlp.data.dataset_readers.dataset_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.babi.html">allennlp.data.dataset_readers.babi</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ccgbank.html">allennlp.data.dataset_readers.ccgbank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2000.html">allennlp.data.dataset_readers.conll2000</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.event2mind.html">allennlp.data.dataset_readers.event2mind</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.interleaving_dataset_reader.html">allennlp.data.dataset_readers.interleaving_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.masked_language_modeling.html">allennlp.data.dataset_readers.masked_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.multiprocess_dataset_reader.html">allennlp.data.dataset_readers.multiprocess_dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.next_token_lm.html">allennlp.data.dataset_readers.next_token_lm</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.ontonotes_ner.html">allennlp.data.dataset_readers.ontonotes_ner</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.penn_tree_bank.html">allennlp.data.dataset_readers.penn_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_dependency_parsing.html">allennlp.data.dataset_readers.semantic_dependency_parsing</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.html">allennlp.data.dataset_readers.semantic_parsing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_parsing.wikitables.html">allennlp.data.dataset_readers.semantic_parsing.wikitables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.simple_language_modeling.html">allennlp.data.dataset_readers.simple_language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.stanford_sentiment_tree_bank.html">allennlp.data.dataset_readers.stanford_sentiment_tree_bank</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies.html">allennlp.data.dataset_readers.universal_dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.universal_dependencies_multilang.html">allennlp.data.dataset_readers.universal_dependencies_multilang</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.quora_paraphrase.html">allennlp.data.dataset_readers.quora_paraphrase</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.copynet_seq2seq.html">allennlp.data.dataset_readers.copynet_seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.text_classification_json.html">allennlp.data.dataset_readers.text_classification_json</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.interpret.html">allennlp.interpret</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.attackers.html">allennlp.interpret.attackers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.interpret.saliency_interpreters.html">allennlp.interpret.saliency_interpreters</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.basic_classifier.html">allennlp.models.basic_classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bert_for_classification.html">allennlp.models.bert_for_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser.html">allennlp.models.biaffine_dependency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biaffine_dependency_parser_multilang.html">allennlp.models.biaffine_dependency_parser_multilang</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.biattentive_classification_network.html">allennlp.models.biattentive_classification_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.bimpm.html">allennlp.models.bimpm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.constituency_parser.html">allennlp.models.constituency_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.ensemble.html">allennlp.models.ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.esim.html">allennlp.models.esim</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.event2mind.html">allennlp.models.event2mind</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.graph_parser.html">allennlp.models.graph_parser</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.language_model.html">allennlp.models.language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.masked_language_model.html">allennlp.models.masked_language_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.next_token_lm.html">allennlp.models.next_token_lm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_parsing.html">allennlp.models.semantic_parsing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.nlvr.html">allennlp.models.semantic_parsing.nlvr</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.wikitables.html">allennlp.models.semantic_parsing.wikitables</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.atis.html">allennlp.models.semantic_parsing.atis</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.models.semantic_parsing.quarel.html">allennlp.models.semantic_parsing.quarel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_bert.html">allennlp.models.srl_bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.srl_util.html">allennlp.models.srl_util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.predictors.html">allennlp.predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo.html">allennlp.modules.elmo</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.language_model_heads.html">allennlp.modules.language_model_heads</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.openai_transformer.html">allennlp.modules.openai_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_decoders.html">allennlp.modules.seq2seq_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.span_extractors.html">allennlp.modules.span_extractors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_bidirectional_lstm.html">allennlp.modules.stacked_bidirectional_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.layer_norm.html">allennlp.modules.layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.pruner.html">allennlp.modules.pruner</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.maxout.html">allennlp.modules.maxout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.input_variational_dropout.html">allennlp.modules.input_variational_dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.bimpm_matching.html">allennlp.modules.bimpm_matching</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.masked_layer_norm.html">allennlp.modules.masked_layer_norm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.sampled_softmax_loss.html">allennlp.modules.sampled_softmax_loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.residual_with_layer_dropout.html">allennlp.modules.residual_with_layer_dropout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.chu_liu_edmonds.html">allennlp.nn.chu_liu_edmonds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.beam_search.html">allennlp.nn.beam_search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.semparse.html">allennlp.semparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.common.html">allennlp.semparse.common</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.contexts.html">allennlp.semparse.contexts</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.type_declarations.html">allennlp.semparse.type_declarations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.worlds.html">allennlp.semparse.worlds</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.executors.html">allennlp.semparse.executors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.domain_languages.html">allennlp.semparse.domain_languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.semparse.util.html">allennlp.semparse.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_simple.html">allennlp.service.server_simple</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.config_explorer.html">allennlp.service.config_explorer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.state_machines.html">allennlp.state_machines</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.states.html">allennlp.state_machines.states</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.trainers.html">allennlp.state_machines.trainers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.state_machines.transition_functions.html">allennlp.state_machines.transition_functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.tools.html">allennlp.tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callbacks.html">allennlp.training.callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.callback_trainer.html">allennlp.training.callback_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.checkpointer.html">allennlp.training.checkpointer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.scheduler.html">allennlp.training.scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.momentum_schedulers.html">allennlp.training.momentum_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metric_tracker.html">allennlp.training.metric_tracker</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.moving_average.html">allennlp.training.moving_average</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.no_op_trainer.html">allennlp.training.no_op_trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.tensorboard_writer.html">allennlp.training.tensorboard_writer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_base.html">allennlp.training.trainer_base</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer_pieces.html">allennlp.training.trainer_pieces</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.util.html">allennlp.training.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.pretrained.html">allennlp.pretrained</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.models.html">allennlp.models</a> &raquo;</li>
        
      <li>allennlp.models.encoder_decoders</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.models.encoder_decoders.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.models.encoder_decoders">
<span id="allennlp-models-encoder-decoders"></span><h1>allennlp.models.encoder_decoders<a class="headerlink" href="#module-allennlp.models.encoder_decoders" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-allennlp.models.encoder_decoders.simple_seq2seq"></span><dl class="class">
<dt id="allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.models.encoder_decoders.simple_seq2seq.</code><code class="sig-name descname">SimpleSeq2Seq</code><span class="sig-paren">(</span><em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em>, <em class="sig-param">source_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder</em>, <em class="sig-param">encoder: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em class="sig-param">max_decoding_steps: int</em>, <em class="sig-param">attention: allennlp.modules.attention.attention.Attention = None</em>, <em class="sig-param">attention_function: allennlp.modules.similarity_functions.similarity_function.SimilarityFunction = None</em>, <em class="sig-param">beam_size: int = None</em>, <em class="sig-param">target_namespace: str = 'tokens'</em>, <em class="sig-param">target_embedding_dim: int = None</em>, <em class="sig-param">scheduled_sampling_ratio: float = 0.0</em>, <em class="sig-param">use_bleu: bool = True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py#L24-L498"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.models.model.html#allennlp.models.model.Model" title="allennlp.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.models.model.Model</span></code></a></p>
<p>This <code class="docutils literal notranslate"><span class="pre">SimpleSeq2Seq</span></code> class is a <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code> which takes a sequence, encodes it, and then
uses the encoded representations to decode another sequence.  You can use this as the basis for
a neural machine translation system, an abstractive summarization system, or any other common
seq2seq problem.  The model here is simple, but should be a decent starting place for
implementing recent models for these tasks.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vocab</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code>, required</span></dt><dd><p>Vocabulary containing source and target vocabularies. They may be under the same namespace
(<cite>tokens</cite>) or the target tokens can have a different namespace, in which case it needs to
be specified as <cite>target_namespace</cite>.</p>
</dd>
<dt><strong>source_embedder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code>, required</span></dt><dd><p>Embedder for source side sequences</p>
</dd>
<dt><strong>encoder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Seq2SeqEncoder</span></code>, required</span></dt><dd><p>The encoder of the “encoder/decoder” model</p>
</dd>
<dt><strong>max_decoding_steps</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code></span></dt><dd><p>Maximum length of decoded sequences.</p>
</dd>
<dt><strong>target_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default = ‘tokens’)</span></dt><dd><p>If the target side vocabulary is different from the source side’s, you need to specify the
target’s namespace here. If not, we’ll assume it is “tokens”, which is also the default
choice for the source side, and this might cause them to share vocabularies.</p>
</dd>
<dt><strong>target_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default = source_embedding_dim)</span></dt><dd><p>You can specify an embedding dimensionality for the target side. If not, we’ll use the same
value as the source embedder’s.</p>
</dd>
<dt><strong>attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code>, optional (default = None)</span></dt><dd><p>If you want to use attention to get a dynamic summary of the encoder outputs at each step
of decoding, this is the function used to compute similarity between the decoder hidden
state and encoder outputs.</p>
</dd>
<dt><strong>attention_function: ``SimilarityFunction``, optional (default = None)</strong></dt><dd><p>This is if you want to use the legacy implementation of attention. This will be deprecated
since it consumes more memory than the specialized attention modules.</p>
</dd>
<dt><strong>beam_size</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default = None)</span></dt><dd><p>Width of the beam for beam search. If not specified, greedy decoding is used.</p>
</dd>
<dt><strong>scheduled_sampling_ratio</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">float</span></code>, optional (default = 0.)</span></dt><dd><p>At each timestep during training, we sample a random number between 0 and 1, and if it is
not less than this value, we use the ground truth labels for the whole batch. Else, we use
the predictions from the previous time step for the whole batch. If this value is 0.0
(default), this corresponds to teacher forcing, and if it is 1.0, it corresponds to not
using target side ground truth labels.  See the following paper for more information:
<a class="reference external" href="https://arxiv.org/abs/1506.03099">Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks. Bengio et al.,
2015</a>.</p>
</dd>
<dt><strong>use_bleu</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">bool</span></code>, optional (default = True)</span></dt><dd><p>If True, the BLEU metric will be calculated during validation.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.decode">
<code class="sig-name descname">decode</code><span class="sig-paren">(</span><em class="sig-param">self, output_dict: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py#L235-L264"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Finalize predictions.</p>
<p>This method overrides <code class="docutils literal notranslate"><span class="pre">Model.decode</span></code>, which gets called after <code class="docutils literal notranslate"><span class="pre">Model.forward</span></code>, at test
time, to finalize predictions. The logic for the decoder part of the encoder-decoder lives
within the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method.</p>
<p>This method trims the output predictions to the first end symbol, replaces indices with
corresponding tokens, and adds a field called <code class="docutils literal notranslate"><span class="pre">predicted_tokens</span></code> to the <code class="docutils literal notranslate"><span class="pre">output_dict</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">self, source_tokens: Dict[str, torch.LongTensor], target_tokens: Dict[str, torch.LongTensor] = None</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py#L191-L233"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make foward pass with decoder logic for producing the entire target sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>source_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code></span></dt><dd><p>The output of <cite>TextField.as_array()</cite> applied on the source <cite>TextField</cite>. This will be
passed through a <cite>TextFieldEmbedder</cite> and then through an encoder.</p>
</dd>
<dt><strong>target_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code>, optional (default = None)</span></dt><dd><p>Output of <cite>Textfield.as_array()</cite> applied on target <cite>TextField</cite>. We assume that the
target tokens are also represented as a <cite>TextField</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>Dict[str, torch.Tensor]</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.get_metrics">
<code class="sig-name descname">get_metrics</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">reset: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, float]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py#L493-L498"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary of metrics. This method will be called by
<code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.training.Trainer</span></code> in order to compute and use model metrics for early
stopping and model serialization.  We return an empty dictionary here rather than raising
as it is not required to implement metrics for a new model.  A boolean <cite>reset</cite> parameter is
passed, as frequently a metric accumulator will have some state which should be reset
between epochs. This is also compatible with <code class="xref py py-class docutils literal notranslate"> <span class="pre">Metrics</span>
<span class="pre">should</span> <span class="pre">be</span> <span class="pre">populated</span> <span class="pre">during</span> <span class="pre">the</span> <span class="pre">call</span> <span class="pre">to</span> <span class="pre">``forward`</span></code>, with the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code> handling the accumulation of the metric until this
method is called.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.take_step">
<code class="sig-name descname">take_step</code><span class="sig-paren">(</span><em class="sig-param">self, last_predictions: torch.Tensor, state: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor]]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/simple_seq2seq.py#L150-L189"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.simple_seq2seq.SimpleSeq2Seq.take_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Take a decoding step. This is called by the beam search class.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>last_predictions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>A tensor of shape <code class="docutils literal notranslate"><span class="pre">(group_size,)</span></code>, which gives the indices of the predictions
during the last time step.</p>
</dd>
<dt><strong>state</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code></span></dt><dd><p>A dictionary of tensors that contain the current state information
needed to predict the next step, which includes the encoder outputs,
the source mask, and the decoder hidden state and context. Each of these
tensors has shape <code class="docutils literal notranslate"><span class="pre">(group_size,</span> <span class="pre">*)</span></code>, where <code class="docutils literal notranslate"><span class="pre">*</span></code> can be any other number
of dimensions.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>Tuple[torch.Tensor, Dict[str, torch.Tensor]]</dt><dd><p>A tuple of <code class="docutils literal notranslate"><span class="pre">(log_probabilities,</span> <span class="pre">updated_state)</span></code>, where <code class="docutils literal notranslate"><span class="pre">log_probabilities</span></code>
is a tensor of shape <code class="docutils literal notranslate"><span class="pre">(group_size,</span> <span class="pre">num_classes)</span></code> containing the predicted
log probability of each class for the next step, for each item in the group,
while <code class="docutils literal notranslate"><span class="pre">updated_state</span></code> is a dictionary of tensors containing the encoder outputs,
source mask, and updated decoder hidden state and context.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>We treat the inputs as a batch, even though <code class="docutils literal notranslate"><span class="pre">group_size</span></code> is not necessarily
equal to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, since the group may contain multiple states
for each source sentence in the batch.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.models.encoder_decoders.copynet_seq2seq"></span><dl class="class">
<dt id="allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.models.encoder_decoders.copynet_seq2seq.</code><code class="sig-name descname">CopyNetSeq2Seq</code><span class="sig-paren">(</span><em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em>, <em class="sig-param">source_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder</em>, <em class="sig-param">encoder: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em class="sig-param">attention: allennlp.modules.attention.attention.Attention</em>, <em class="sig-param">beam_size: int</em>, <em class="sig-param">max_decoding_steps: int</em>, <em class="sig-param">target_embedding_dim: int = 30</em>, <em class="sig-param">copy_token: str = '&#64;COPY&#64;'</em>, <em class="sig-param">source_namespace: str = 'source_tokens'</em>, <em class="sig-param">target_namespace: str = 'target_tokens'</em>, <em class="sig-param">tensor_based_metric: allennlp.training.metrics.metric.Metric = None</em>, <em class="sig-param">token_based_metric: allennlp.training.metrics.metric.Metric = None</em>, <em class="sig-param">initializer: allennlp.nn.initializers.InitializerApplicator = &lt;allennlp.nn.initializers.InitializerApplicator object&gt;</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/copynet_seq2seq.py#L24-L835"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.models.model.html#allennlp.models.model.Model" title="allennlp.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.models.model.Model</span></code></a></p>
<p>This is an implementation of <a class="reference external" href="https://arxiv.org/pdf/1603.06393">CopyNet</a>.
CopyNet is a sequence-to-sequence encoder-decoder model with a copying mechanism
that can copy tokens from the source sentence into the target sentence instead of
generating all target tokens only from the target vocabulary.</p>
<p>It is very similar to a typical seq2seq model used in neural machine translation
tasks, for example, except that in addition to providing a “generation” score at each timestep
for the tokens in the target vocabulary, it also provides a “copy” score for each
token that appears in the source sentence. In other words, you can think of CopyNet
as a seq2seq model with a dynamic target vocabulary that changes based on the tokens
in the source sentence, allowing it to predict tokens that are out-of-vocabulary (OOV)
with respect to the actual target vocab.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vocab</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code>, required</span></dt><dd><p>Vocabulary containing source and target vocabularies.</p>
</dd>
<dt><strong>source_embedder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code>, required</span></dt><dd><p>Embedder for source side sequences</p>
</dd>
<dt><strong>encoder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Seq2SeqEncoder</span></code>, required</span></dt><dd><p>The encoder of the “encoder/decoder” model</p>
</dd>
<dt><strong>attention</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Attention</span></code>, required</span></dt><dd><p>This is used to get a dynamic summary of encoder outputs at each timestep
when producing the “generation” scores for the target vocab.</p>
</dd>
<dt><strong>beam_size</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required</span></dt><dd><p>Beam width to use for beam search prediction.</p>
</dd>
<dt><strong>max_decoding_steps</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, required</span></dt><dd><p>Maximum sequence length of target predictions.</p>
</dd>
<dt><strong>target_embedding_dim</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">int</span></code>, optional (default = 30)</span></dt><dd><p>The size of the embeddings for the target vocabulary.</p>
</dd>
<dt><strong>copy_token</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default = ‘&#64;COPY&#64;’)</span></dt><dd><p>The token used to indicate that a target token was copied from the source.
If this token is not already in your target vocabulary, it will be added.</p>
</dd>
<dt><strong>source_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default = ‘source_tokens’)</span></dt><dd><p>The namespace for the source vocabulary.</p>
</dd>
<dt><strong>target_namespace</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default = ‘target_tokens’)</span></dt><dd><p>The namespace for the target vocabulary.</p>
</dd>
<dt><strong>tensor_based_metric</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Metric</span></code>, optional (default = BLEU)</span></dt><dd><p>A metric to track on validation data that takes raw tensors when its called.
This metric must accept two arguments when called: a batched tensor
of predicted token indices, and a batched tensor of gold token indices.</p>
</dd>
<dt><strong>token_based_metric</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Metric</span></code>, optional (default = None)</span></dt><dd><p>A metric to track on validation data that takes lists of lists of tokens
as input. This metric must accept two arguments when called, both
of type <cite>List[List[str]]</cite>. The first is a predicted sequence for each item
in the batch and the second is a gold sequence for each item in the batch.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">InitializerApplicator</span></code>, optional</span></dt><dd><p>An initialization strategy for the model weights.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.decode">
<code class="sig-name descname">decode</code><span class="sig-paren">(</span><em class="sig-param">self, output_dict: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/copynet_seq2seq.py#L813-L825"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Finalize predictions.</p>
<p>After a beam search, the predicted indices correspond to tokens in the target vocabulary
OR tokens in source sentence. Here we gather the actual tokens corresponding to
the indices.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">self, source_tokens: Dict[str, torch.LongTensor], source_token_ids: torch.Tensor, source_to_target: torch.Tensor, metadata: List[Dict[str, Any]], target_tokens: Dict[str, torch.LongTensor] = None, target_token_ids: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/copynet_seq2seq.py#L151-L224"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make foward pass with decoder logic for producing the entire target sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>source_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code>, required</span></dt><dd><p>The output of <cite>TextField.as_array()</cite> applied on the source <cite>TextField</cite>. This will be
passed through a <cite>TextFieldEmbedder</cite> and then through an encoder.</p>
</dd>
<dt><strong>source_token_ids</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, required</span></dt><dd><p>Tensor containing IDs that indicate which source tokens match each other.
Has shape: <cite>(batch_size, trimmed_source_length)</cite>.</p>
</dd>
<dt><strong>source_to_target</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, required</span></dt><dd><p>Tensor containing vocab index of each source token with respect to the
target vocab namespace. Shape: <cite>(batch_size, trimmed_source_length)</cite>.</p>
</dd>
<dt><strong>metadata</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]]</span></code>, required</span></dt><dd><p>Metadata field that contains the original source tokens with key ‘source_tokens’
and any other meta fields. When ‘target_tokens’ is also passed, the metadata
should also contain the original target tokens with key ‘target_tokens’.</p>
</dd>
<dt><strong>target_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code>, optional (default = None)</span></dt><dd><p>Output of <cite>Textfield.as_array()</cite> applied on target <cite>TextField</cite>. We assume that the
target tokens are also represented as a <cite>TextField</cite> which must contain a “tokens”
key that uses single ids.</p>
</dd>
<dt><strong>target_token_ids</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>, optional (default = None)</span></dt><dd><p>A tensor of shape <cite>(batch_size, target_sequence_length)</cite> which indicates which
tokens in the target sequence match tokens in the source sequence.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>Dict[str, torch.Tensor]</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.get_metrics">
<code class="sig-name descname">get_metrics</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">reset: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, float]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/copynet_seq2seq.py#L827-L835"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary of metrics. This method will be called by
<code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.training.Trainer</span></code> in order to compute and use model metrics for early
stopping and model serialization.  We return an empty dictionary here rather than raising
as it is not required to implement metrics for a new model.  A boolean <cite>reset</cite> parameter is
passed, as frequently a metric accumulator will have some state which should be reset
between epochs. This is also compatible with <code class="xref py py-class docutils literal notranslate"> <span class="pre">Metrics</span>
<span class="pre">should</span> <span class="pre">be</span> <span class="pre">populated</span> <span class="pre">during</span> <span class="pre">the</span> <span class="pre">call</span> <span class="pre">to</span> <span class="pre">``forward`</span></code>, with the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code> handling the accumulation of the metric until this
method is called.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.take_search_step">
<code class="sig-name descname">take_search_step</code><span class="sig-paren">(</span><em class="sig-param">self, last_predictions: torch.Tensor, state: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor]]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/copynet_seq2seq.py#L688-L777"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.copynet_seq2seq.CopyNetSeq2Seq.take_search_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Take step during beam search.</p>
<p>This function is what gets passed to the <cite>BeamSearch.search</cite> method. It takes
predictions from the last timestep and the current state and outputs
the log probabilities assigned to tokens for the next timestep, as well as the updated
state.</p>
<p>Since we are predicting tokens out of the extended vocab (target vocab + all unique
tokens from the source sentence), this is a little more complicated that just
making a forward pass through the model. The output log probs will have
shape <cite>(group_size, target_vocab_size + trimmed_source_length)</cite> so that each
token in the target vocab and source sentence are assigned a probability.</p>
<p>Note that copy scores are assigned to each source token based on their position, not unique value.
So if a token appears more than once in the source sentence, it will have more than one score.
Further, if a source token is also part of the target vocab, its final score
will be the sum of the generation and copy scores. Therefore, in order to
get the score for all tokens in the extended vocab at this step,
we have to combine copy scores for re-occuring source tokens and potentially
add them to the generation scores for the matching token in the target vocab, if
there is one.</p>
<p>So we can break down the final log probs output as the concatenation of two
matrices, A: <cite>(group_size, target_vocab_size)</cite>, and B: <cite>(group_size, trimmed_source_length)</cite>.
Matrix A contains the sum of the generation score and copy scores (possibly 0)
for each target token. Matrix B contains left-over copy scores for source tokens
that do NOT appear in the target vocab, with zeros everywhere else. But since
a source token may appear more than once in the source sentence, we also have to
sum the scores for each appearance of each unique source token. So matrix B
actually only has non-zero values at the first occurence of each source token
that is not in the target vocab.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>last_predictions</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code></span></dt><dd><p>Shape: <cite>(group_size,)</cite></p>
</dd>
<dt><strong>state</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code></span></dt><dd><p>Contains all state tensors necessary to produce generation and copy scores
for next step.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><cite>group_size</cite> != <cite>batch_size</cite>. In fact, <cite>group_size</cite> = <cite>batch_size * beam_size</cite>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.models.encoder_decoders.composed_seq2seq"></span><dl class="class">
<dt id="allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq">
<em class="property">class </em><code class="sig-prename descclassname">allennlp.models.encoder_decoders.composed_seq2seq.</code><code class="sig-name descname">ComposedSeq2Seq</code><span class="sig-paren">(</span><em class="sig-param">vocab: allennlp.data.vocabulary.Vocabulary</em>, <em class="sig-param">source_text_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder</em>, <em class="sig-param">encoder: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em class="sig-param">decoder: allennlp.modules.seq2seq_decoders.seq_decoder.SeqDecoder</em>, <em class="sig-param">tied_source_embedder_key: Optional[str] = None</em>, <em class="sig-param">initializer: allennlp.nn.initializers.InitializerApplicator = &lt;allennlp.nn.initializers.InitializerApplicator object&gt;</em>, <em class="sig-param">regularizer: Optional[allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/composed_seq2seq.py#L16-L149"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.models.model.html#allennlp.models.model.Model" title="allennlp.models.model.Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.models.model.Model</span></code></a></p>
<p>This <code class="docutils literal notranslate"><span class="pre">ComposedSeq2Seq</span></code> class is a <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code> which takes a sequence, encodes it, and then
uses the encoded representations to decode another sequence.  You can use this as the basis for
a neural machine translation system, an abstractive summarization system, or any other common
seq2seq problem.  The model here is simple, but should be a decent starting place for
implementing recent models for these tasks.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ComposedSeq2Seq</span></code> class composes separate <code class="docutils literal notranslate"><span class="pre">Seq2SeqEncoder</span></code> and <code class="docutils literal notranslate"><span class="pre">SeqDecoder</span></code> classes.
These parts are customizable and are independent from each other.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vocab</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Vocabulary</span></code>, required</span></dt><dd><p>Vocabulary containing source and target vocabularies. They may be under the same namespace
(<cite>tokens</cite>) or the target tokens can have a different namespace, in which case it needs to
be specified as <cite>target_namespace</cite>.</p>
</dd>
<dt><strong>source_text_embedders</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">TextFieldEmbedder</span></code>, required</span></dt><dd><p>Embedders for source side sequences</p>
</dd>
<dt><strong>encoder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Seq2SeqEncoder</span></code>, required</span></dt><dd><p>The encoder of the “encoder/decoder” model</p>
</dd>
<dt><strong>decoder</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">SeqDecoder</span></code>, required</span></dt><dd><p>The decoder of the “encoder/decoder” model</p>
</dd>
<dt><strong>tied_source_embedder_key</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">str</span></code>, optional (default=``None``)</span></dt><dd><p>If specified, this key is used to obtain token_embedder in <cite>source_text_embedder</cite> and
the weights are shared/tied with the decoder’s target embedding weights.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">InitializerApplicator</span></code>, optional (default=``InitializerApplicator()``)</span></dt><dd><p>Used to initialize the model parameters.</p>
</dd>
<dt><strong>regularizer</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">RegularizerApplicator</span></code>, optional (default=``None``)</span></dt><dd><p>If provided, will be used to calculate the regularization penalty during training.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.decode">
<code class="sig-name descname">decode</code><span class="sig-paren">(</span><em class="sig-param">self, output_dict: Dict[str, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/composed_seq2seq.py#L111-L116"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Finalize predictions.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">self, source_tokens: Dict[str, torch.LongTensor], target_tokens: Dict[str, torch.LongTensor] = None</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/composed_seq2seq.py#L85-L109"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make foward pass on the encoder and decoder for producing the entire target sequence.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>source_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code></span></dt><dd><p>The output of <cite>TextField.as_array()</cite> applied on the source <cite>TextField</cite>. This will be
passed through a <cite>TextFieldEmbedder</cite> and then through an encoder.</p>
</dd>
<dt><strong>target_tokens</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">torch.LongTensor]</span></code>, optional (default = None)</span></dt><dd><p>Output of <cite>Textfield.as_array()</cite> applied on target <cite>TextField</cite>. We assume that the
target tokens are also represented as a <cite>TextField</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>Dict[str, torch.Tensor]</dt><dd><p>The output tensors from the decoder.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.get_metrics">
<code class="sig-name descname">get_metrics</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">reset: bool = False</em><span class="sig-paren">)</span> &#x2192; Dict[str, float]<a class="reference external" href="https://github.com/allenai/allennlp/blob/master/allennlp/models/encoder_decoders/composed_seq2seq.py#L147-L149"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.encoder_decoders.composed_seq2seq.ComposedSeq2Seq.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary of metrics. This method will be called by
<code class="xref py py-class docutils literal notranslate"><span class="pre">allennlp.training.Trainer</span></code> in order to compute and use model metrics for early
stopping and model serialization.  We return an empty dictionary here rather than raising
as it is not required to implement metrics for a new model.  A boolean <cite>reset</cite> parameter is
passed, as frequently a metric accumulator will have some state which should be reset
between epochs. This is also compatible with <code class="xref py py-class docutils literal notranslate"> <span class="pre">Metrics</span>
<span class="pre">should</span> <span class="pre">be</span> <span class="pre">populated</span> <span class="pre">during</span> <span class="pre">the</span> <span class="pre">call</span> <span class="pre">to</span> <span class="pre">``forward`</span></code>, with the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code> handling the accumulation of the metric until this
method is called.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.models.ensemble.html" class="btn btn-neutral float-right" title="allennlp.models.ensemble" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.models.decomposable_attention.html" class="btn btn-neutral float-left" title="allennlp.models.decomposable_attention" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Allen Institute for Artificial Intelligence

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>